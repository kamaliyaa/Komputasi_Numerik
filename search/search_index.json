{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang Di halaman Saya \u00b6 Nama : Kamaliya NIM : 180411100030 Kelas : Komputasi Numerik 4B Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : Jln.Sukun VI ,Perumnas Kamal \u00b6 \u200b","title":"index"},{"location":"#selamat-datang-di-halaman-saya","text":"Nama : Kamaliya NIM : 180411100030 Kelas : Komputasi Numerik 4B Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : Jln.Sukun VI ,Perumnas Kamal","title":"Selamat Datang Di halaman Saya"},{"location":"#_1","text":"\u200b","title":""},{"location":"EULER/","text":"PERSAMAAN DIFFERENSIAL BIASA DENGAN METODE EULER \u00b6 Persamaan differensial adalah pesamaan yang memuat turunan satu (atau beberapa ) fungsi yang tidak diketahui. Suatu persamaan diferensial yang terdiri dari satu variabel bebas saja dinamakan perasamaan diferensial biasa (Ordinary Differential Equation-ODE).Penyelesaian persamaan deferensial biasa dengan metode Euler adalah proses mencari nilai fungsi y(x) pada titik x tertentu dari persamaan deferensial f(x,y) yang di ketahui dengan menggunakan persamaan umum persamaan 2. Penyelesaian persamaan diferensial biasa (ODE) mempunyai bentuk umum yaitu : Metode euler atau disebut juga metode orde pertama karena persamaannya kita hanya dapat mengambil sampai suku orde pertama saja. CONTOH SOAL \u00b6 Buatlah program untuk menyelesaikan persamaan differensial biasa berikut dengan menggunakan metode Euler. Untuk menentukan y(1.01), y(1.02) dan y(1.03). PROGRAM PYTHON \u00b6 print ( \"f(x,y)=1+x^2\" ) print ( \"yi+1 = y1 + hf(xi+yi)\" ) x1 = float ( input ( \"Masukkan x1= \" )) x2 = float ( input ( \"Masukkan x2= \" )) h = 1.01 - x1 #Langsung saya atur sendiri karena yang dicari f(x,y) nilai x-nya=1.01 n = 4 #jumlah x ada 4 yaitu 1, 1.01, 1.02, 1.03 xi = - 4 hasil = xi y = 0 for i in range ( n ): print ( \"hasil dari y\" + str ( i ) + \"= \" + str ( hasil )) hasil = xi + h * ( 1 + ( x1 + y ) ** 2 ) y += h xi = hasil Pada bagian pertama terdapat variable x1 adalah x awal dan x2 merupakan x akhir. karena di soal terdapat nx=3 yaitu x0=1, x1=1,01, x3=1,02 x2=1,03 maka h= xn-x0/n, hasilnya h = 0.01. xi adalah hasil awal yang kemudian akan dimasukkan pada prosess iterasi. Karena rumus eurel adalah y1 = y0 +h(f(x,y)) maka rumus barunya adalah y1=y0+h(1+x^2). variable y digunakan untuk penambahan nilai x agar selalu bertambah 0.01.","title":"EULER"},{"location":"EULER/#persamaan-differensial-biasa-dengan-metode-euler","text":"Persamaan differensial adalah pesamaan yang memuat turunan satu (atau beberapa ) fungsi yang tidak diketahui. Suatu persamaan diferensial yang terdiri dari satu variabel bebas saja dinamakan perasamaan diferensial biasa (Ordinary Differential Equation-ODE).Penyelesaian persamaan deferensial biasa dengan metode Euler adalah proses mencari nilai fungsi y(x) pada titik x tertentu dari persamaan deferensial f(x,y) yang di ketahui dengan menggunakan persamaan umum persamaan 2. Penyelesaian persamaan diferensial biasa (ODE) mempunyai bentuk umum yaitu : Metode euler atau disebut juga metode orde pertama karena persamaannya kita hanya dapat mengambil sampai suku orde pertama saja.","title":"PERSAMAAN DIFFERENSIAL BIASA DENGAN METODE EULER"},{"location":"EULER/#contoh-soal","text":"Buatlah program untuk menyelesaikan persamaan differensial biasa berikut dengan menggunakan metode Euler. Untuk menentukan y(1.01), y(1.02) dan y(1.03).","title":"CONTOH SOAL"},{"location":"EULER/#program-python","text":"print ( \"f(x,y)=1+x^2\" ) print ( \"yi+1 = y1 + hf(xi+yi)\" ) x1 = float ( input ( \"Masukkan x1= \" )) x2 = float ( input ( \"Masukkan x2= \" )) h = 1.01 - x1 #Langsung saya atur sendiri karena yang dicari f(x,y) nilai x-nya=1.01 n = 4 #jumlah x ada 4 yaitu 1, 1.01, 1.02, 1.03 xi = - 4 hasil = xi y = 0 for i in range ( n ): print ( \"hasil dari y\" + str ( i ) + \"= \" + str ( hasil )) hasil = xi + h * ( 1 + ( x1 + y ) ** 2 ) y += h xi = hasil Pada bagian pertama terdapat variable x1 adalah x awal dan x2 merupakan x akhir. karena di soal terdapat nx=3 yaitu x0=1, x1=1,01, x3=1,02 x2=1,03 maka h= xn-x0/n, hasilnya h = 0.01. xi adalah hasil awal yang kemudian akan dimasukkan pada prosess iterasi. Karena rumus eurel adalah y1 = y0 +h(f(x,y)) maka rumus barunya adalah y1=y0+h(1+x^2). variable y digunakan untuk penambahan nilai x agar selalu bertambah 0.01.","title":"PROGRAM PYTHON"},{"location":"Gauss/","text":"METODE ELIMINASI GAUSS \u00b6 Eliminasi Gauss ialah sebuah cara mengoperasikan nilai-nilai yang berada di dalam matriks sehingga dapat menjadi matriks yang lebih sederhana. Caranya ialah melakukan operasi baris sehingga matriks tersebut menjadi matriks yang eselon-baris. Ini dapat digunakan sebagai salah satu metode penyelesaian persamaan linear dengan menggunakan matriks Caranya dengan mengubah persamaan linear tersebut ke dalam matriks teraugmentasi dan mengoperasikannya. Setelah menjadi matriks Eselon-baris, lakukan substitusi balik untuk mendapatkan nilai dari variabel-variabel tersebut. Metode ini berangkat dari kenyataan bahwa bila matriks A berbentuk segitiga atas (menggunakan Operasi Baris Elementer) seperti system persamaan berikut ini: Maka solusinya dapat dihitung dengan teknik penyulingan mundur ( backward substitution ): kondisi sangat penting. Sebab bila persamaan diatas menjerjakan pembagian dengan nol. Apabila kondisi tersebut tidak dipenuhi, maka SPL tidak mempunyai jawaban ELIMINASI GAUSS JORDAN \u00b6 \u200b Dalam aljabar linear, eliminasi Gauss-Jordan adalah versi dari eliminasi Gauss. Pada metode eliminasi Gauss-Jordan kita membuat nol elemen-elemen di bawah maupun di atas diagonal utama suatu matriks. Hasilnya adalah matriks tereduksi yang berupa matriks diagonal satuan (semua elemen pada diagonal utama bernilai 1, elemen-elemen lainnya nol). Dalam bentuk matriks, eliminasi Gauss-Jordan ditulis sebagai berikut: listing program : import numpy as np #Definisi Matrix A = [] B = [] n = int(input(\"Masukkan ukuran Matrix: \")) for i in range(n): baris=[] for i in range(n): a=int(input(\"Masukkan Nilai: \")) baris.append(a) A.append(baris) for i in range(n): h = int(input(\"Masukkan Hasil: \")) B.append(h) Matrix=np.array(A,float) Hasil=np.array(B,float) n=len(Matrix) #Eliminasi Gauss for k in range(0,n-1): for i in range(k+1,n): if Matrix[i,k]!=0 : lam=Matrix[i,k]/Matrix[k,k] Matrix[i,k:n]=Matrix[i,k:n]-(Matrix[k,k:n]*lam) Hasil[i]=Hasil[i]-(Hasil[k]*lam) print(\"Matrix A : \",'\\n',Matrix) #Subtitution x=np.zeros(n,float) for m in range(n-1,-1,-1): x[m]=(Hasil[m]-np.dot(Matrix[m, m+1:n], x[m+1:n]))/Matrix[m,m] print('Nilai X ',m+1, '=',x[m]) Masukkan ukuran Matrix : 3 Masukkan Nilai : 2 Masukkan Nilai : - 2 Masukkan Nilai : 5 Masukkan Nilai : 1 Masukkan Nilai : 5 Masukkan Nilai : 2 Masukkan Nilai : 4 Masukkan Nilai : 5 Masukkan Nilai : 2 Masukkan Hasil : 12 Masukkan Hasil : 3 Masukkan Hasil : - 4 Matrix A : [[ 2. - 2. 5. ] [ 0. 6. - 0.5 ] [ 0. 0. - 7.25 ]] Nilai X 3 = 3.2413793103448274 Nilai X 2 = - 0.2298850574712644 Nilai X 1 = - 2.333333333333332 jadi panjang Matrix yang dibuat dalam Program Diatas adalah 3 variabel. |2 -2 5| |12| |1 5 2|=| 3 | |4 5 2| |-4| pivot yang dibentuk adalah a1.1,a2.2,dan a3.3 sehingga semua angka yang ada dibawah pivot akan dikonversikan menjadi nol sesuai hasil program dan hasil dari persamaan diatas menghasilkan x1=-2.333333333, x2=-0.22988505 dan x3=3.2413793 ELIMINASI GAUSS JACOBI \u00b6 Metode Jacobi, adalah metode tak langsung atau metode iteratif yang melakukan perbaharuan nilai x yang diperoleh tiap iterasi (mirip metode substitusi berurutan). Metode ini hampir sama dengan metode Gauss Seidel, namun tidak melibatkan perhitungan implisit. Metode ini merupakan suatu teknik penyelesaian SPL berukuran n x n, AX = b, secara iteratif. Proses penyelesaian dimulai dengan suatu hampiran awal terhadap penyelesaian, X0, kemudian membentuk suatu serangkaian vector X1, X2, \u2026 yang konvergen ke X. Metode ini ditemukan oleh Matematikawan yang berasal dari Jerman,Carl,Gustav,Jacobi. Penemuan ini diperkirakan pada tahun 1800-an from pprint import pprint from numpy import array , zeros , diag , diagflat , dot import numpy as np def jacobi ( A , b , N = 25 , x = None ): #Membuat iniial guess if x is None : x = zeros ( len ( A [ 0 ])) #Membuat vektor dari elemen matrix A D = diag ( A ) R = A - diagflat ( D ) #Iterasi for i in range ( N ): x = ( b - dot ( R , x )) / D return x Mat1 = [] Mat2 = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) Mat1 . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) Mat2 . append ( h ) A = array ( Mat1 , float ) b = array ( Mat2 , float ) x = len ( Mat1 ) guess = np . zeros ( x , float ) sol = jacobi ( A , b , N = 25 , x = guess ) print ( \"A:\" ) pprint ( A ) print ( \"b:\" ) pprint ( b ) print ( \"x:\" ) pprint ( sol ) Masukkan ukuran Matrix : 3 Masukkan Nilai : 3 Masukkan Nilai : 1 Masukkan Nilai : - 1 Masukkan Nilai : 4 Masukkan Nilai : 7 Masukkan Nilai : - 3 Masukkan Nilai : 2 Masukkan Nilai : - 2 Masukkan Nilai : 5 Masukkan Hasil : 5 Masukkan Hasil : 20 Masukkan Hasil : 10 A : array ([[ 3. , 1. , - 1. ], [ 4. , 7. , - 3. ], [ 2. , - 2. , 5. ]]) b : array ([ 5. , 20. , 10. ]) x : array ([ 1.50602413 , 3.13253016 , 2.6506024 ]) ELIMINASI GAUSS SEIDEL \u00b6 Metode iterasi Gauss-Seidel adalah metode yang menggunakan proses iterasi hingga diperoleh nilai-nilai yang berubah-ubah dan akhirnya relatif konstan. Metode iterasi Gauss-Seidel dikembangkan dari gagasan metode iterasi pada solusi persamaan tak linier. Gauss ini mempunyai kelebihan dan kekurangan. kelebihannya yaitu Metode eliminasi gauss-seidel digunakan untuk menyelesaikan SPL yang berukuran kecil karena metode ini lebih efisien. Dengan metode iterasi Gauss-Seidel toleransi pembulatan dapat diperkecil karena iterasi dapat diteruskan sampai seteliti mungkin sesuai dengan batas toleransi yang diinginkan. kekurangannya yaitu Kelemahan dari metode ini adalah masalah pivot (titik tengah) yang harus benar\u2013benar diperhatikan, karena penyusunan yang salah akan menyebabkan iterasi menjadi divergen dan tidak diperoleh hasil yang benar def seidel ( a , x , b ): #Mencari Panjang Matrix n = len ( a ) for j in range ( 0 , n ): d = b [ j ] #Menghitung xi, yi, zi for i in range ( 0 , n ): if ( j != i ): d -= a [ j ][ i ] * x [ i ] x [ j ] = d / a [ j ][ j ] #Solusi return x m = int ( input ( \"Masukkan Panjang Matrix: \" )) a = [] b = [] for k in range ( m ): mat1 = [] for i in range ( m ): l = float ( input ( \"Masukkan a\" + str ( k + 1 ) + \",\" + str ( i + 1 ) + \": \" )) mat1 . append ( l ) h = float ( input ( \"Masukkan Hasil: \" )) b . append ( h ) a . append ( mat1 ) n = 3 x = [ 0 , 0 , 0 ] print ( x ) for i in range ( 0 , 100 ): x = seidel ( a , x , b ) print ( x ) Masukkan Panjang Matrix : 3 Masukkan a1 , 1 : 4 Masukkan a1 , 2 : - 1 Masukkan a1 , 3 : 1 Masukkan Hasil : 7 Masukkan a2 , 1 : 4 Masukkan a2 , 2 : - 8 Masukkan a2 , 3 : 1 Masukkan Hasil : - 21 Masukkan a3 , 1 : - 2 Masukkan a3 , 2 : 1 Masukkan a3 , 3 : 5 Masukkan Hasil : 15 [ 0 , 0 , 0 ] [ 1.75 , 3.5 , 3.0 ] [ 1.875 , 3.9375 , 2.9625 ] [ 1.99375 , 3.9921875 , 2.9990625 ] [ 1.99828125 , 3.9990234375 , 2.9995078125 ] [ 1.99987890625 , 3.9998779296875 , 2.9999759765625003 ] [ 1.99997548828125 , 3.9999847412109375 , 2.999993247070312 ] [ 1.9999978735351562 , 3.9999980926513667 , 2.999999530883789 ] [ 1.9999996404418945 , 3.9999997615814205 , 2.9999999038604734 ] [ 1.9999999644302369 , 3.9999999701976776 , 2.9999999917325595 ] [ 1.9999999946162794 , 3.9999999962747097 , 2.99999999859157 ] [ 1.9999999994207849 , 3.9999999995343387 , 2.9999999998614464 ] [ 1.9999999999182232 , 3.999999999941793 , 2.999999999978931 ] [ 1.9999999999907154 , 3.999999999992724 , 2.9999999999977414 ] [ 1.9999999999987457 , 3.9999999999990905 , 2.9999999999996803 ] [ 1.9999999999998526 , 3.9999999999998863 , 2.9999999999999636 ] [ 1.9999999999999807 , 3.999999999999986 , 2.999999999999995 ] [ 1.9999999999999978 , 3.9999999999999987 , 2.9999999999999996 ] [ 1.9999999999999996 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ]","title":"Gauss"},{"location":"Gauss/#metode-eliminasi-gauss","text":"Eliminasi Gauss ialah sebuah cara mengoperasikan nilai-nilai yang berada di dalam matriks sehingga dapat menjadi matriks yang lebih sederhana. Caranya ialah melakukan operasi baris sehingga matriks tersebut menjadi matriks yang eselon-baris. Ini dapat digunakan sebagai salah satu metode penyelesaian persamaan linear dengan menggunakan matriks Caranya dengan mengubah persamaan linear tersebut ke dalam matriks teraugmentasi dan mengoperasikannya. Setelah menjadi matriks Eselon-baris, lakukan substitusi balik untuk mendapatkan nilai dari variabel-variabel tersebut. Metode ini berangkat dari kenyataan bahwa bila matriks A berbentuk segitiga atas (menggunakan Operasi Baris Elementer) seperti system persamaan berikut ini: Maka solusinya dapat dihitung dengan teknik penyulingan mundur ( backward substitution ): kondisi sangat penting. Sebab bila persamaan diatas menjerjakan pembagian dengan nol. Apabila kondisi tersebut tidak dipenuhi, maka SPL tidak mempunyai jawaban","title":"METODE ELIMINASI GAUSS"},{"location":"Gauss/#eliminasi-gauss-jordan","text":"\u200b Dalam aljabar linear, eliminasi Gauss-Jordan adalah versi dari eliminasi Gauss. Pada metode eliminasi Gauss-Jordan kita membuat nol elemen-elemen di bawah maupun di atas diagonal utama suatu matriks. Hasilnya adalah matriks tereduksi yang berupa matriks diagonal satuan (semua elemen pada diagonal utama bernilai 1, elemen-elemen lainnya nol). Dalam bentuk matriks, eliminasi Gauss-Jordan ditulis sebagai berikut: listing program : import numpy as np #Definisi Matrix A = [] B = [] n = int(input(\"Masukkan ukuran Matrix: \")) for i in range(n): baris=[] for i in range(n): a=int(input(\"Masukkan Nilai: \")) baris.append(a) A.append(baris) for i in range(n): h = int(input(\"Masukkan Hasil: \")) B.append(h) Matrix=np.array(A,float) Hasil=np.array(B,float) n=len(Matrix) #Eliminasi Gauss for k in range(0,n-1): for i in range(k+1,n): if Matrix[i,k]!=0 : lam=Matrix[i,k]/Matrix[k,k] Matrix[i,k:n]=Matrix[i,k:n]-(Matrix[k,k:n]*lam) Hasil[i]=Hasil[i]-(Hasil[k]*lam) print(\"Matrix A : \",'\\n',Matrix) #Subtitution x=np.zeros(n,float) for m in range(n-1,-1,-1): x[m]=(Hasil[m]-np.dot(Matrix[m, m+1:n], x[m+1:n]))/Matrix[m,m] print('Nilai X ',m+1, '=',x[m]) Masukkan ukuran Matrix : 3 Masukkan Nilai : 2 Masukkan Nilai : - 2 Masukkan Nilai : 5 Masukkan Nilai : 1 Masukkan Nilai : 5 Masukkan Nilai : 2 Masukkan Nilai : 4 Masukkan Nilai : 5 Masukkan Nilai : 2 Masukkan Hasil : 12 Masukkan Hasil : 3 Masukkan Hasil : - 4 Matrix A : [[ 2. - 2. 5. ] [ 0. 6. - 0.5 ] [ 0. 0. - 7.25 ]] Nilai X 3 = 3.2413793103448274 Nilai X 2 = - 0.2298850574712644 Nilai X 1 = - 2.333333333333332 jadi panjang Matrix yang dibuat dalam Program Diatas adalah 3 variabel. |2 -2 5| |12| |1 5 2|=| 3 | |4 5 2| |-4| pivot yang dibentuk adalah a1.1,a2.2,dan a3.3 sehingga semua angka yang ada dibawah pivot akan dikonversikan menjadi nol sesuai hasil program dan hasil dari persamaan diatas menghasilkan x1=-2.333333333, x2=-0.22988505 dan x3=3.2413793","title":"ELIMINASI GAUSS JORDAN"},{"location":"Gauss/#eliminasi-gauss-jacobi","text":"Metode Jacobi, adalah metode tak langsung atau metode iteratif yang melakukan perbaharuan nilai x yang diperoleh tiap iterasi (mirip metode substitusi berurutan). Metode ini hampir sama dengan metode Gauss Seidel, namun tidak melibatkan perhitungan implisit. Metode ini merupakan suatu teknik penyelesaian SPL berukuran n x n, AX = b, secara iteratif. Proses penyelesaian dimulai dengan suatu hampiran awal terhadap penyelesaian, X0, kemudian membentuk suatu serangkaian vector X1, X2, \u2026 yang konvergen ke X. Metode ini ditemukan oleh Matematikawan yang berasal dari Jerman,Carl,Gustav,Jacobi. Penemuan ini diperkirakan pada tahun 1800-an from pprint import pprint from numpy import array , zeros , diag , diagflat , dot import numpy as np def jacobi ( A , b , N = 25 , x = None ): #Membuat iniial guess if x is None : x = zeros ( len ( A [ 0 ])) #Membuat vektor dari elemen matrix A D = diag ( A ) R = A - diagflat ( D ) #Iterasi for i in range ( N ): x = ( b - dot ( R , x )) / D return x Mat1 = [] Mat2 = [] n = int ( input ( \"Masukkan ukuran Matrix: \" )) for i in range ( n ): baris = [] for i in range ( n ): a = int ( input ( \"Masukkan Nilai: \" )) baris . append ( a ) Mat1 . append ( baris ) for i in range ( n ): h = int ( input ( \"Masukkan Hasil: \" )) Mat2 . append ( h ) A = array ( Mat1 , float ) b = array ( Mat2 , float ) x = len ( Mat1 ) guess = np . zeros ( x , float ) sol = jacobi ( A , b , N = 25 , x = guess ) print ( \"A:\" ) pprint ( A ) print ( \"b:\" ) pprint ( b ) print ( \"x:\" ) pprint ( sol ) Masukkan ukuran Matrix : 3 Masukkan Nilai : 3 Masukkan Nilai : 1 Masukkan Nilai : - 1 Masukkan Nilai : 4 Masukkan Nilai : 7 Masukkan Nilai : - 3 Masukkan Nilai : 2 Masukkan Nilai : - 2 Masukkan Nilai : 5 Masukkan Hasil : 5 Masukkan Hasil : 20 Masukkan Hasil : 10 A : array ([[ 3. , 1. , - 1. ], [ 4. , 7. , - 3. ], [ 2. , - 2. , 5. ]]) b : array ([ 5. , 20. , 10. ]) x : array ([ 1.50602413 , 3.13253016 , 2.6506024 ])","title":"ELIMINASI GAUSS JACOBI"},{"location":"Gauss/#eliminasi-gauss-seidel","text":"Metode iterasi Gauss-Seidel adalah metode yang menggunakan proses iterasi hingga diperoleh nilai-nilai yang berubah-ubah dan akhirnya relatif konstan. Metode iterasi Gauss-Seidel dikembangkan dari gagasan metode iterasi pada solusi persamaan tak linier. Gauss ini mempunyai kelebihan dan kekurangan. kelebihannya yaitu Metode eliminasi gauss-seidel digunakan untuk menyelesaikan SPL yang berukuran kecil karena metode ini lebih efisien. Dengan metode iterasi Gauss-Seidel toleransi pembulatan dapat diperkecil karena iterasi dapat diteruskan sampai seteliti mungkin sesuai dengan batas toleransi yang diinginkan. kekurangannya yaitu Kelemahan dari metode ini adalah masalah pivot (titik tengah) yang harus benar\u2013benar diperhatikan, karena penyusunan yang salah akan menyebabkan iterasi menjadi divergen dan tidak diperoleh hasil yang benar def seidel ( a , x , b ): #Mencari Panjang Matrix n = len ( a ) for j in range ( 0 , n ): d = b [ j ] #Menghitung xi, yi, zi for i in range ( 0 , n ): if ( j != i ): d -= a [ j ][ i ] * x [ i ] x [ j ] = d / a [ j ][ j ] #Solusi return x m = int ( input ( \"Masukkan Panjang Matrix: \" )) a = [] b = [] for k in range ( m ): mat1 = [] for i in range ( m ): l = float ( input ( \"Masukkan a\" + str ( k + 1 ) + \",\" + str ( i + 1 ) + \": \" )) mat1 . append ( l ) h = float ( input ( \"Masukkan Hasil: \" )) b . append ( h ) a . append ( mat1 ) n = 3 x = [ 0 , 0 , 0 ] print ( x ) for i in range ( 0 , 100 ): x = seidel ( a , x , b ) print ( x ) Masukkan Panjang Matrix : 3 Masukkan a1 , 1 : 4 Masukkan a1 , 2 : - 1 Masukkan a1 , 3 : 1 Masukkan Hasil : 7 Masukkan a2 , 1 : 4 Masukkan a2 , 2 : - 8 Masukkan a2 , 3 : 1 Masukkan Hasil : - 21 Masukkan a3 , 1 : - 2 Masukkan a3 , 2 : 1 Masukkan a3 , 3 : 5 Masukkan Hasil : 15 [ 0 , 0 , 0 ] [ 1.75 , 3.5 , 3.0 ] [ 1.875 , 3.9375 , 2.9625 ] [ 1.99375 , 3.9921875 , 2.9990625 ] [ 1.99828125 , 3.9990234375 , 2.9995078125 ] [ 1.99987890625 , 3.9998779296875 , 2.9999759765625003 ] [ 1.99997548828125 , 3.9999847412109375 , 2.999993247070312 ] [ 1.9999978735351562 , 3.9999980926513667 , 2.999999530883789 ] [ 1.9999996404418945 , 3.9999997615814205 , 2.9999999038604734 ] [ 1.9999999644302369 , 3.9999999701976776 , 2.9999999917325595 ] [ 1.9999999946162794 , 3.9999999962747097 , 2.99999999859157 ] [ 1.9999999994207849 , 3.9999999995343387 , 2.9999999998614464 ] [ 1.9999999999182232 , 3.999999999941793 , 2.999999999978931 ] [ 1.9999999999907154 , 3.999999999992724 , 2.9999999999977414 ] [ 1.9999999999987457 , 3.9999999999990905 , 2.9999999999996803 ] [ 1.9999999999998526 , 3.9999999999998863 , 2.9999999999999636 ] [ 1.9999999999999807 , 3.999999999999986 , 2.999999999999995 ] [ 1.9999999999999978 , 3.9999999999999987 , 2.9999999999999996 ] [ 1.9999999999999996 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ] [ 2.0 , 4.0 , 3.0 ]","title":"ELIMINASI GAUSS SEIDEL"},{"location":"Mengukur%20Jarak/","text":"Mengukur Jarak Data \u00b6 Mengukur Jarak Numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance \u00b6 kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski Distance.Minkowski Distance dinyatakan dengan $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Uuclidean Distance \u00b6 Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini Average Distance \u00b6 Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,yx,y dalam ruang dimensi nn, rata-rata jarak didefinisikan dengan Average Distance $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Manhattan distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ \u00b6 Weighted euclidean distance \u00b6 Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ dimana wi adalah bobot yang diberikan pada atribut ke i Chord distance \u00b6 Chord distance adalah satu ukuran dengan jarak modifikasi Euclidean distance agar mengatasi kekurangan dari Euclidean distance. dipecahkan juga dengan cara skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ dimana \u2225x\u22252\u2016x\u20162 adalah L2-norm\u2225x\u22252= $$ L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum { i = 1 }^{ n }x_{i}^{2}} $$ MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} }); \u200b \u200b","title":"mengukur jarak"},{"location":"Mengukur%20Jarak/#mengukur-jarak-data","text":"","title":"Mengukur Jarak Data"},{"location":"Mengukur%20Jarak/#mengukur-jarak-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya","title":"Mengukur Jarak Numerik"},{"location":"Mengukur%20Jarak/#minkowski-distance","text":"kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski Distance.Minkowski Distance dinyatakan dengan $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$","title":"Minkowski Distance"},{"location":"Mengukur%20Jarak/#uuclidean-distance","text":"Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini","title":"Uuclidean Distance"},{"location":"Mengukur%20Jarak/#average-distance","text":"Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,yx,y dalam ruang dimensi nn, rata-rata jarak didefinisikan dengan Average Distance $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Average Distance"},{"location":"Mengukur%20Jarak/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Manhattan distance"},{"location":"Mengukur%20Jarak/#_1","text":"","title":""},{"location":"Mengukur%20Jarak/#weighted-euclidean-distance","text":"Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ dimana wi adalah bobot yang diberikan pada atribut ke i","title":"Weighted euclidean distance"},{"location":"Mengukur%20Jarak/#chord-distance","text":"Chord distance adalah satu ukuran dengan jarak modifikasi Euclidean distance agar mengatasi kekurangan dari Euclidean distance. dipecahkan juga dengan cara skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ dimana \u2225x\u22252\u2016x\u20162 adalah L2-norm\u2225x\u22252= $$ L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum { i = 1 }^{ n }x_{i}^{2}} $$ MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} }); \u200b \u200b","title":"Chord distance"},{"location":"Metode%20Monte%20Carlo/","text":"Metode Monte Carlo \u00b6 Metode Monte Carlo adalah algoritma komputasi yang mengandalkan pengambilan sampel acak berulang untuk mendapatkan hasil numerik. Penggunaan metode ini adalah untuk mengevaluasi integral definit, terutama integral multidimensi dengan syarat dan batasan yang rumit. Metode ini terbukti efisien dalam memecahkan persamaan diferensial integral medan radians, sehingga metode ini digunakan dalam perhitungan iluminasi global yang menghasilkan gambar-gambar fotorealistik model tiga dimensi, dimana diterapkan dalam video games, arsitektur, perancangan, film yang dihasilkan oleh komputer, efek-efek khusus dalam film, bisnis, ekonomi, dan bidang lainnya. Karena algoritma ini memerlukan pengulangan (repetisi) dan perhitungan yang amat kompleks, metode Monte Carlo pada umumnya dilakukan menggunakan komputer, dan memakai berbagai teknik simulasi komputer. Estimation of Areas and Volumes by Monte Carlo \u00b6 Langkah-langkah metode Monte Carlo \u00b6 Mendefinisikan distribusi probabilitas dati datamasa lalu atau dari distribusi teoritis. Mengkonversikan distribusi kedalam frekuensikumulatif. Melakukan simulasi dengan bilangan acak. Menganalisa keluaran simulasi. Tugas Pemrograman \u00b6 Buatlah program untuk memverifikasi secara numerik bahwa Gunakan metode monte carlo dan 2500 angka acak. Listing Program \u00b6 from scipy import random import numpy as np import matplotlib.pyplot as plt b = 0 a = 2 n = 2500 def fungsi ( x ): return ( 4 - x ** 2 ) ** 0.5 area = [] for i in range ( n ): xacak = np . zeros ( n ) for i in range ( len ( xacak )): xacak [ i ] = random . uniform ( b , a ) integral = 0.0 for i in range ( n ): integral += fungsi ( xacak [ i ]) jawab = ( a - b ) / float ( n ) * integral area . append ( jawab ) plt . title ( \"Hasil phi\" ) plt . hist ( area , bins = 30 , ec = 'black' ) plt . xlabel ( \"Area\" ) plt . show () Hasil Program \u00b6 Gunakan metode monte carlo untuk memperkirakan integral Listing Program \u00b6 from scipy import random import numpy as np a = - 1 b = 1 N = 100 xrand = np . zeros ( N ) yrand = np . zeros ( N ) zrand = np . zeros ( N ) integral = 0.0 for i in range ( 4 ): for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) for i in range ( len ( yrand )): yrand [ i ] = random . uniform ( a , b ) for i in range ( len ( zrand )): zrand [ i ] = random . uniform ( a , b ) def func ( x , y , z ): return ( x ** 2 ) + ( y ** 2 ) + ( z ** 2 ) for i in range ( N ): integral += func ( xrand [ i ], yrand [ i ], zrand [ i ]) jawab = ( b - a ) / float ( N ) * integral print ( \"jawab: \" , jawab ) Hasil program \u00b6 jawab : 7.951233160381278","title":"Metode Monte Carlo"},{"location":"Metode%20Monte%20Carlo/#metode-monte-carlo","text":"Metode Monte Carlo adalah algoritma komputasi yang mengandalkan pengambilan sampel acak berulang untuk mendapatkan hasil numerik. Penggunaan metode ini adalah untuk mengevaluasi integral definit, terutama integral multidimensi dengan syarat dan batasan yang rumit. Metode ini terbukti efisien dalam memecahkan persamaan diferensial integral medan radians, sehingga metode ini digunakan dalam perhitungan iluminasi global yang menghasilkan gambar-gambar fotorealistik model tiga dimensi, dimana diterapkan dalam video games, arsitektur, perancangan, film yang dihasilkan oleh komputer, efek-efek khusus dalam film, bisnis, ekonomi, dan bidang lainnya. Karena algoritma ini memerlukan pengulangan (repetisi) dan perhitungan yang amat kompleks, metode Monte Carlo pada umumnya dilakukan menggunakan komputer, dan memakai berbagai teknik simulasi komputer.","title":"Metode Monte Carlo"},{"location":"Metode%20Monte%20Carlo/#estimation-of-areas-and-volumes-by-monte-carlo","text":"","title":"Estimation of Areas and Volumes by Monte Carlo"},{"location":"Metode%20Monte%20Carlo/#langkah-langkah-metode-monte-carlo","text":"Mendefinisikan distribusi probabilitas dati datamasa lalu atau dari distribusi teoritis. Mengkonversikan distribusi kedalam frekuensikumulatif. Melakukan simulasi dengan bilangan acak. Menganalisa keluaran simulasi.","title":"Langkah-langkah metode Monte Carlo"},{"location":"Metode%20Monte%20Carlo/#tugas-pemrograman","text":"Buatlah program untuk memverifikasi secara numerik bahwa Gunakan metode monte carlo dan 2500 angka acak.","title":"Tugas Pemrograman"},{"location":"Metode%20Monte%20Carlo/#listing-program","text":"from scipy import random import numpy as np import matplotlib.pyplot as plt b = 0 a = 2 n = 2500 def fungsi ( x ): return ( 4 - x ** 2 ) ** 0.5 area = [] for i in range ( n ): xacak = np . zeros ( n ) for i in range ( len ( xacak )): xacak [ i ] = random . uniform ( b , a ) integral = 0.0 for i in range ( n ): integral += fungsi ( xacak [ i ]) jawab = ( a - b ) / float ( n ) * integral area . append ( jawab ) plt . title ( \"Hasil phi\" ) plt . hist ( area , bins = 30 , ec = 'black' ) plt . xlabel ( \"Area\" ) plt . show ()","title":"Listing Program"},{"location":"Metode%20Monte%20Carlo/#hasil-program","text":"Gunakan metode monte carlo untuk memperkirakan integral","title":"Hasil Program"},{"location":"Metode%20Monte%20Carlo/#listing-program_1","text":"from scipy import random import numpy as np a = - 1 b = 1 N = 100 xrand = np . zeros ( N ) yrand = np . zeros ( N ) zrand = np . zeros ( N ) integral = 0.0 for i in range ( 4 ): for i in range ( len ( xrand )): xrand [ i ] = random . uniform ( a , b ) for i in range ( len ( yrand )): yrand [ i ] = random . uniform ( a , b ) for i in range ( len ( zrand )): zrand [ i ] = random . uniform ( a , b ) def func ( x , y , z ): return ( x ** 2 ) + ( y ** 2 ) + ( z ** 2 ) for i in range ( N ): integral += func ( xrand [ i ], yrand [ i ], zrand [ i ]) jawab = ( b - a ) / float ( N ) * integral print ( \"jawab: \" , jawab )","title":"Listing Program"},{"location":"Metode%20Monte%20Carlo/#hasil-program_1","text":"jawab : 7.951233160381278","title":"Hasil program"},{"location":"Metode%20Romberg/","text":"Metode Romberg \u00b6 Metode Romberg adalah metode perhitungan yang didasarkan oleh trapezional rule dan error calcultion sehingga memperoleh nilai integral dengan tingkat presisi yang tinggi. Metode ini dipakai untuk evaluasi numerik dari integral tentu. Metode integrasi Romberg ini didasarkan pada perluasan ekstrapolasi Richardson untuk memperoleh nilai integrasi yang semakin baik. Pada setiap penerapan ekstrapolasi Richardson akan menaikan galat pada hasil solusinya sebesar dua, misal Untuk dua interval bagian yang berbeda yang panjangnya h1 dan h2 akan diperoleh aproksimasi nilai-nilai I1 dan I2 . Kemudian diperoleh kekeliruan E1 dan E2. Algoritma : \u00b6 1) Cari nilai A0,A2\u2026..Ak berdasarkan n, dimana : n=2^k = jumlah interasi, dan dimana k /pias =(0,1,2,3,4,5,6) 2) Tentukan nilai tabel iterasi, dimana : r = iterasi ke- Xr = h = ( b-a ) / n fr = Xr yang telah dimasukan ke dalam fungsi / integral Contoh Soal : \u00b6 Code Program : \u00b6 # import numpy and scipy.integrate import numpy as np from integrate import scipy gfg = lambda x : np . exp ( - x * * 2 ) + 1 / np . sqrt ( np . pi ) # using scipy.integrate.romberg() geek = integrate . romberg ( gfg , 1 , 2 , show = True ) print ( geek ) Integrasi Romberg dari <function vectorize1..vfunc at 0x00000209E1605400> dari [1, 2] Langkah StepSize Hasil 1 1,000000 0,757287 2 0,500000 0,713438 0,698822 4 0.250000 0.702909 0.699400 0.699438 8 0.125000 0.700310 0.699444 0.699447 0.699447 16 0,062500 0,699663 0,699447 0,699447 0,699447 0,699447 32 0.031250 0.699501 0.699447 0.699447 0.699447 0.699447 0.699447 Hasil akhir adalah 0,6994468414978009 setelah 33 evaluasi fungsi","title":"Metode Romberg"},{"location":"Metode%20Romberg/#metode-romberg","text":"Metode Romberg adalah metode perhitungan yang didasarkan oleh trapezional rule dan error calcultion sehingga memperoleh nilai integral dengan tingkat presisi yang tinggi. Metode ini dipakai untuk evaluasi numerik dari integral tentu. Metode integrasi Romberg ini didasarkan pada perluasan ekstrapolasi Richardson untuk memperoleh nilai integrasi yang semakin baik. Pada setiap penerapan ekstrapolasi Richardson akan menaikan galat pada hasil solusinya sebesar dua, misal Untuk dua interval bagian yang berbeda yang panjangnya h1 dan h2 akan diperoleh aproksimasi nilai-nilai I1 dan I2 . Kemudian diperoleh kekeliruan E1 dan E2.","title":"Metode Romberg"},{"location":"Metode%20Romberg/#algoritma","text":"1) Cari nilai A0,A2\u2026..Ak berdasarkan n, dimana : n=2^k = jumlah interasi, dan dimana k /pias =(0,1,2,3,4,5,6) 2) Tentukan nilai tabel iterasi, dimana : r = iterasi ke- Xr = h = ( b-a ) / n fr = Xr yang telah dimasukan ke dalam fungsi / integral","title":"Algoritma :"},{"location":"Metode%20Romberg/#contoh-soal","text":"","title":"Contoh Soal :"},{"location":"Metode%20Romberg/#code-program","text":"# import numpy and scipy.integrate import numpy as np from integrate import scipy gfg = lambda x : np . exp ( - x * * 2 ) + 1 / np . sqrt ( np . pi ) # using scipy.integrate.romberg() geek = integrate . romberg ( gfg , 1 , 2 , show = True ) print ( geek ) Integrasi Romberg dari <function vectorize1..vfunc at 0x00000209E1605400> dari [1, 2] Langkah StepSize Hasil 1 1,000000 0,757287 2 0,500000 0,713438 0,698822 4 0.250000 0.702909 0.699400 0.699438 8 0.125000 0.700310 0.699444 0.699447 0.699447 16 0,062500 0,699663 0,699447 0,699447 0,699447 0,699447 32 0.031250 0.699501 0.699447 0.699447 0.699447 0.699447 0.699447 Hasil akhir adalah 0,6994468414978009 setelah 33 evaluasi fungsi","title":"Code Program :"},{"location":"Richardson%20Extrapolation/","text":"Richardson Extrapolation \u00b6 Dalam analisis numerik, ekstrapolasi Richardson adalah metode percepatan urutan , yang digunakan untuk meningkatkan laju konvergensi suatu urutan. ekstrapolasi Richardson termasuk integrasiRomberg , yang menerapkan ekstrapolasi Richardson pada aturan trapesium , dan algoritma Bulirsch-Stoer untuk menyelesaikan persamaan diferensial biasa. Contoh Program Richardson Extrapolation \u00b6 from math import * def zeros ( n , m ): Z = [] for i in range ( n ): Z . append ([ 0 ] * m ) return Z def D ( Func , a , h ): return ( Func ( a + h ) - Func ( a - h )) / ( 2 * h ) def Richardson_dif ( func , a ): '''Richardson extrapolation method for numerical calculation of first derivative ''' k = 9 L = zeros ( k , k ) for I in range ( k ): L [ I ][ 0 ] = D ( func , a , 1 / ( 2 ** ( I + 1 ))) for j in range ( 1 , k ): for i in range ( k - j ): L [ i ][ j ] = (( 4 * ( j )) * L [ i + 1 ][ j - 1 ] - L [ i ][ j - 1 ]) / ( 4 * ( j ) - 1 ) return L [ 0 ][ k - 1 ] print ( '>>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<<' ) print ( \"=======================================================================\" ) print ( 'f = -0.1*x*4-0.15*x3-0.5*x*2-0.25*x+1.2 dengan x = 0.5' ) print ( \"=======================================================================\" ) print ( ' %04.20f ' % Richardson_dif ( lambda x : - 0.1 * x * 4 - 0.15 * x3 - 0.5 * x * 2 - 0.25 * x + 1.2 , 0.5 )) print ( \"=======================================================================\" ) print ( 'diff(2*cos(pi+sin(x)) dengan x = pi/2 adalah = %04.20f ' % Richardson_dif ( lambda x : 2 * cos ( pi + sin ( x )), pi / 3 )) Hasil Running \u00b6 >>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<< ======================================================================= f = - 0.1 * x * 4 - 0.15 * x3 - 0.5 * x * 2 - 0.25 * x + 1.2 dengan x = 0.5 ======================================================================= - 0.91250000000000530687 ======================================================================= diff ( 2 ** cos ( pi + sin ( x )) dengan x = pi / 2 adalah = 0.16849558398154249050 [ Program finished ]","title":"Richardson Extrapolation"},{"location":"Richardson%20Extrapolation/#richardson-extrapolation","text":"Dalam analisis numerik, ekstrapolasi Richardson adalah metode percepatan urutan , yang digunakan untuk meningkatkan laju konvergensi suatu urutan. ekstrapolasi Richardson termasuk integrasiRomberg , yang menerapkan ekstrapolasi Richardson pada aturan trapesium , dan algoritma Bulirsch-Stoer untuk menyelesaikan persamaan diferensial biasa.","title":"Richardson Extrapolation"},{"location":"Richardson%20Extrapolation/#contoh-program-richardson-extrapolation","text":"from math import * def zeros ( n , m ): Z = [] for i in range ( n ): Z . append ([ 0 ] * m ) return Z def D ( Func , a , h ): return ( Func ( a + h ) - Func ( a - h )) / ( 2 * h ) def Richardson_dif ( func , a ): '''Richardson extrapolation method for numerical calculation of first derivative ''' k = 9 L = zeros ( k , k ) for I in range ( k ): L [ I ][ 0 ] = D ( func , a , 1 / ( 2 ** ( I + 1 ))) for j in range ( 1 , k ): for i in range ( k - j ): L [ i ][ j ] = (( 4 * ( j )) * L [ i + 1 ][ j - 1 ] - L [ i ][ j - 1 ]) / ( 4 * ( j ) - 1 ) return L [ 0 ][ k - 1 ] print ( '>>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<<' ) print ( \"=======================================================================\" ) print ( 'f = -0.1*x*4-0.15*x3-0.5*x*2-0.25*x+1.2 dengan x = 0.5' ) print ( \"=======================================================================\" ) print ( ' %04.20f ' % Richardson_dif ( lambda x : - 0.1 * x * 4 - 0.15 * x3 - 0.5 * x * 2 - 0.25 * x + 1.2 , 0.5 )) print ( \"=======================================================================\" ) print ( 'diff(2*cos(pi+sin(x)) dengan x = pi/2 adalah = %04.20f ' % Richardson_dif ( lambda x : 2 * cos ( pi + sin ( x )), pi / 3 ))","title":"Contoh Program Richardson Extrapolation"},{"location":"Richardson%20Extrapolation/#hasil-running","text":">>>>>>>>>>>>>>>>>>>>>>> DIFERENSIASI NUMERIK DARI <<<<<<<<<<<<<<<<<<<<< ======================================================================= f = - 0.1 * x * 4 - 0.15 * x3 - 0.5 * x * 2 - 0.25 * x + 1.2 dengan x = 0.5 ======================================================================= - 0.91250000000000530687 ======================================================================= diff ( 2 ** cos ( pi + sin ( x )) dengan x = pi / 2 adalah = 0.16849558398154249050 [ Program finished ]","title":"Hasil Running"},{"location":"Statistik%20Dekriptif/","text":"Statistik Deskriptif \u00b6 Pengertian \u00b6 Pengertian statistik deskriptif metode pengumpulan sebuah data data yang akan menghasilkan informasi yang berguna Tipe statistik deskriptif \u00b6 Mean(Rata-rata) Mean atau rata rata adalah sebuah nilai yang jumlah dari semua angka atau data dapat di bagi dari banyak data itu .misal memiliki N data dapat di hitung dengan rumus mean sebagai berikut : $$ \\begin{align} \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i={a_1+a_2+a_3+a_4+........+a_n \\over n} \\end{align} $$ keterangan: x=rata-rata a=nilai ke N n=banyak nilai atau data Median median merupakan nilai tengah (pusat data) dalam suatu data median biasanya bisa disebut Me .menghitung median mempunyai 2 metode yaitu ketika N atau jumlah data ganjil atau genap. saat data ganjil dan data genap perhitingan nya berbeda.berikut rumus median yang dapat di gunakan : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ keterangan: me =median atau nilai tengah n=banyak data Modus \u00b6 Modus adalah nilai yang sering muncul dalam himpunan data dan jika hasil dengan jumlah nilai tertinggi maka itu merupakan modus dari himpunan angka. brikut ini rumus mencari modus dalam himpunan data : $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ ket; mo=nilai modus tb= tepi bawah b1=selisih frekuensi antara nilai mudus dengan elemen sebelumnya b2=selisih frekuensi antara nilai mudus dengan elemen sesudahnya p= panjang interval Varian \u00b6 Varian adalah penyebaran nilai dalam suatu data dari rata rata .berikut ini rumus yang dapat di gunakan : $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Keterangan: x=rata rata Xi=rata rata dari semua titik data n= banyak dari anggota data \u200b Standart Deviasi \u00b6 Standar deviasi adalah ukuran kumpulan data relatif terhadap rata-rata atau akar kuadrat positif dari varian. standar deviasi di hitung dengan cara mengakar kuadrat nilai dari varians. dengan menggunakan rumus standar varian berikut : $$ t {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$ Skewness \u00b6 adalah ketidaksimetrisan atau kemiringan pada suatu kurva yang tampak condong ke kiri atau ke kanan. Skewness bisa dihitung menggunakan rumus sebagai berikut: $$ {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ Quartile \u00b6 Quartile adalah irisan nilai dari hasil pembagian data menjadi empat bagian yang sama besar.quartil terbagi menjadi tiga yaitu quartil pertama,kedua,dan ketiga. $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Penerapan Statistik Deskriptif Menggunakan Python \u00b6 Alat dan Bahan \u00b6 Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini, library python yang digunakan adalah sebagai berikut: pertama : pandas, digunakan untuk data manajemen dan data analysis. kedua : scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika. lebih jelasnya bisa di lihat di bawah ini : \u00b6 import pandas as pd from scipy import stats df = pd . read_csv ( \"liya.csv\" , sep = ',' ) data = { \"Stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () Hasil Running \u00b6 stats Laki-Laki Perempuan Tinggi Badan Berat Badan Min 20 20 150 50 Max 40 30 180 75 Mean 30.01 25.06 165.284 62.61 Standard Deviasi 6.21 3.08 8.83 7.6 Variasi 38.57 9.46 77.92 57.81 Skewnes -0.07 0.01 -0.11 -0.02 Quantile 1 25 23 157 57 Quantile 2 30 25 166 62 Quantile 3 36 28 173 70 Median 30 25 166 62 Modus 37 24 167 57 MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} });","title":"statistik deskriptif"},{"location":"Statistik%20Dekriptif/#statistik-deskriptif","text":"","title":"Statistik Deskriptif"},{"location":"Statistik%20Dekriptif/#pengertian","text":"Pengertian statistik deskriptif metode pengumpulan sebuah data data yang akan menghasilkan informasi yang berguna","title":"Pengertian"},{"location":"Statistik%20Dekriptif/#tipe-statistik-deskriptif","text":"Mean(Rata-rata) Mean atau rata rata adalah sebuah nilai yang jumlah dari semua angka atau data dapat di bagi dari banyak data itu .misal memiliki N data dapat di hitung dengan rumus mean sebagai berikut : $$ \\begin{align} \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i={a_1+a_2+a_3+a_4+........+a_n \\over n} \\end{align} $$ keterangan: x=rata-rata a=nilai ke N n=banyak nilai atau data Median median merupakan nilai tengah (pusat data) dalam suatu data median biasanya bisa disebut Me .menghitung median mempunyai 2 metode yaitu ketika N atau jumlah data ganjil atau genap. saat data ganjil dan data genap perhitingan nya berbeda.berikut rumus median yang dapat di gunakan : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ keterangan: me =median atau nilai tengah n=banyak data","title":"Tipe statistik deskriptif"},{"location":"Statistik%20Dekriptif/#modus","text":"Modus adalah nilai yang sering muncul dalam himpunan data dan jika hasil dengan jumlah nilai tertinggi maka itu merupakan modus dari himpunan angka. brikut ini rumus mencari modus dalam himpunan data : $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ ket; mo=nilai modus tb= tepi bawah b1=selisih frekuensi antara nilai mudus dengan elemen sebelumnya b2=selisih frekuensi antara nilai mudus dengan elemen sesudahnya p= panjang interval","title":"Modus"},{"location":"Statistik%20Dekriptif/#varian","text":"Varian adalah penyebaran nilai dalam suatu data dari rata rata .berikut ini rumus yang dapat di gunakan : $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Keterangan: x=rata rata Xi=rata rata dari semua titik data n= banyak dari anggota data \u200b","title":"Varian"},{"location":"Statistik%20Dekriptif/#standart-deviasi","text":"Standar deviasi adalah ukuran kumpulan data relatif terhadap rata-rata atau akar kuadrat positif dari varian. standar deviasi di hitung dengan cara mengakar kuadrat nilai dari varians. dengan menggunakan rumus standar varian berikut : $$ t {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$","title":"Standart Deviasi"},{"location":"Statistik%20Dekriptif/#skewness","text":"adalah ketidaksimetrisan atau kemiringan pada suatu kurva yang tampak condong ke kiri atau ke kanan. Skewness bisa dihitung menggunakan rumus sebagai berikut: $$ {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$","title":"Skewness"},{"location":"Statistik%20Dekriptif/#quartile","text":"Quartile adalah irisan nilai dari hasil pembagian data menjadi empat bagian yang sama besar.quartil terbagi menjadi tiga yaitu quartil pertama,kedua,dan ketiga. $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$","title":"Quartile"},{"location":"Statistik%20Dekriptif/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan Statistik Deskriptif Menggunakan Python"},{"location":"Statistik%20Dekriptif/#alat-dan-bahan","text":"Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini, library python yang digunakan adalah sebagai berikut: pertama : pandas, digunakan untuk data manajemen dan data analysis. kedua : scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika. lebih jelasnya bisa di lihat di bawah ini :","title":"Alat dan Bahan"},{"location":"Statistik%20Dekriptif/#_1","text":"import pandas as pd from scipy import stats df = pd . read_csv ( \"liya.csv\" , sep = ',' ) data = { \"Stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index ()","title":""},{"location":"Statistik%20Dekriptif/#hasil-running","text":"stats Laki-Laki Perempuan Tinggi Badan Berat Badan Min 20 20 150 50 Max 40 30 180 75 Mean 30.01 25.06 165.284 62.61 Standard Deviasi 6.21 3.08 8.83 7.6 Variasi 38.57 9.46 77.92 57.81 Skewnes -0.07 0.01 -0.11 -0.02 Quantile 1 25 23 157 57 Quantile 2 30 25 166 62 Quantile 3 36 28 173 70 Median 30 25 166 62 Modus 37 24 167 57 MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} });","title":"Hasil Running"},{"location":"clus/","text":"CLUSTERING CATEGORICAL DATA \u00b6 Clustering adalah sebuah proses untuk mengelompokan data ke dalam beberapa cluster atau kelompok sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum. Metode K-Means Clustering \u00b6 K-Means Clustering adalah suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang melakukan pengelompokan data dengan sistem partisi.Metode K-Means Clustering berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Karakteristik dari algoritma ini adalah : Memiliki n buah data Input berupa jumlah data dan jumlah cluster (kelompok) Pada setiap cluster / kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Algoritma K-Means \u00b6 Secara sederhana algoritma K-Means dimulai dari tahap berikut : Tentukan titik yang akan di jadikan jumlah cluster. Alokasikan data ke dalam cluster secara random. Hitung centroid/rata-rata dari data yang ada di masing-masing cluster. Alokasikan masing-masing data ke centroid/rata-rata terdekat. Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai centroid, ada yang di atas nilai threshold yang ditentukan atau apabila perubahan nilai pada objective function yang digunakan di atas nilai threshold yang ditentukan Permasalahan yang terdapat pada K-Means \u00b6 Ditemukannya beberapa model clustering yang berbeda Pemilihan jumlah cluster yang paling tepat Kegagalan untuk converge Outliers Bentuk cluster Overlapping Karakterristik K-Mein \u00b6 K-Means sangat cepat dalam proses clustering K-Means sangat sensitif pada pembangkitan centroid awal secara random Memungkinkan suatu cluster tidak mempunyai anggota Hasil clustering dengan K-Means bersifat tidak unik (selalu berubah-ubah) \u2013 terkadang baik, terkadang jelek K-means sangat sulit untuk mencapai global optimum Rumus K-Means \u00b6 Metode K-Modes \u00b6 K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster. Rumus K-Modes \u00b6 Metode K-Prototype \u00b6 Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu. Rumus K-Prototype \u00b6 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"clustering"},{"location":"clus/#clustering-categorical-data","text":"Clustering adalah sebuah proses untuk mengelompokan data ke dalam beberapa cluster atau kelompok sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum.","title":"CLUSTERING CATEGORICAL DATA"},{"location":"clus/#metode-k-means-clustering","text":"K-Means Clustering adalah suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang melakukan pengelompokan data dengan sistem partisi.Metode K-Means Clustering berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Karakteristik dari algoritma ini adalah : Memiliki n buah data Input berupa jumlah data dan jumlah cluster (kelompok) Pada setiap cluster / kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut.","title":"Metode K-Means Clustering"},{"location":"clus/#algoritma-k-means","text":"Secara sederhana algoritma K-Means dimulai dari tahap berikut : Tentukan titik yang akan di jadikan jumlah cluster. Alokasikan data ke dalam cluster secara random. Hitung centroid/rata-rata dari data yang ada di masing-masing cluster. Alokasikan masing-masing data ke centroid/rata-rata terdekat. Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai centroid, ada yang di atas nilai threshold yang ditentukan atau apabila perubahan nilai pada objective function yang digunakan di atas nilai threshold yang ditentukan","title":"Algoritma K-Means"},{"location":"clus/#permasalahan-yang-terdapat-pada-k-means","text":"Ditemukannya beberapa model clustering yang berbeda Pemilihan jumlah cluster yang paling tepat Kegagalan untuk converge Outliers Bentuk cluster Overlapping","title":"Permasalahan yang terdapat pada K-Means"},{"location":"clus/#karakterristik-k-mein","text":"K-Means sangat cepat dalam proses clustering K-Means sangat sensitif pada pembangkitan centroid awal secara random Memungkinkan suatu cluster tidak mempunyai anggota Hasil clustering dengan K-Means bersifat tidak unik (selalu berubah-ubah) \u2013 terkadang baik, terkadang jelek K-means sangat sulit untuk mencapai global optimum","title":"Karakterristik  K-Mein"},{"location":"clus/#rumus-k-means","text":"","title":"Rumus K-Means"},{"location":"clus/#metode-k-modes","text":"K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster.","title":"Metode K-Modes"},{"location":"clus/#rumus-k-modes","text":"","title":"Rumus K-Modes"},{"location":"clus/#metode-k-prototype","text":"Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu.","title":"Metode K-Prototype"},{"location":"clus/#rumus-k-prototype","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Rumus K-Prototype"},{"location":"error/","text":"ERROR DALAM KOMPUTASI NUMERIK \u00b6 ERROR \u00b6 Komputasi numerik bisa di artikan dengan penentuan eror suatu perhitungan agar bisa mencapai nilai akurasi. eror ini ialah nilai yang disebabkan nilai menjadi tidak tepat. Penyebab Terjadinya Error \u00b6 Error dapat terjadi karena beberapa kesalahan. Berikut ini penjelasan mengenai ketiga sumber kesalahan dalam komputasi numerik. Round off errors Kesalahan jenis ini terjadi akibat proses pembulatan dalam perhitungan. Secara umum, proses pembulatan ada 2 aturan yaitu Jika digit yang dibulatkan kurang dari 5, maka tidak terjadi pembulatan. Sebaliknya, jika lebih dari 5, maka terjadi pembulatan yaitu dengan menambah satu. Truncation errors Truncation errors adalah kesalahan yang dilakukan dengan memotong jumlah tak hingga dan memperkirakannya dengan jumlah terbatas. Inherent errors Terjadi akibat kekeliruan dalam menyalin data, salah membaca skala atau kesalahan karena kurangnya pengertian mengenai hukum-hukum fisik dari data yang diukur. Kesalahan ini sering terjadi karena faktor human error DERET MACLAURIN \u00b6 Deret MacLaurin adalah Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret Taylor. Perhitungan e 2x \u00b6 Dalam banyak masalah terapan, pilihan basis yang mudah digunakan adalah bilangan irasional e = 2,718281828... Bilangan ini disebut basis natural. Fungsi f ( x ) = ex disebut sebagai fungsi eksponensial natural. Gambar 7 menunjukkan grafik fungsi ini. Pastikan bahwa dalam melihat fungsi eksponensial f ( x ) = ex , e adalah konstanta 2,718281828\u2026, sedangkan x adalah variabel. f(x)=ex f'(x) = ex maka f'(0) = 1 f\u201d(x) = ex maka f\u201d(0) = 1 f\u201d'(x) = ex maka f\u201d'(0) = 1 Untuk bilangan e 2x maka: jadi, kesimpulannya adalah sebagai berikut: ketika nilai x diganti dengan 4 maka hasilnya adalah 296,99. Listing Program \u00b6 Untuk membuat program agar dapat mengekspansi bilangan e 2x dengan nilai x=4 hingga nilai menjadi kurang dari 0,001 bisa dibuat dengan listing program sebagai berikut. import math x = int ( input ( \"masukan nilai x=\" )) cek = 1 a = 0 b = 1 while cek > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 3 ** i ) * x ** i / math . factorial ( i ) for j in range ( b ): f_y += ( 3 ** j ) * x ** j / math . factorial ( j ) print ( \"suku ke\" , a , \"=\" , f_x ) print ( \"suku ke\" , b , \"=\" , f_y ) cek = f_y - f_x a += 1 b += 1 print ( \"hasil selisih =\" , cek ) dan berikut hasil output nya : masukan nilai x = 1 suku ke 0 = 0 suku ke 1 = 1.0 hasil selisih = 1.0 suku ke 1 = 1.0 suku ke 2 = 4.0 hasil selisih = 3.0 suku ke 2 = 4.0 suku ke 3 = 8.5 hasil selisih = 4.5 suku ke 3 = 8.5 suku ke 4 = 13.0 hasil selisih = 4.5 suku ke 4 = 13.0 suku ke 5 = 16.375 hasil selisih = 3.375 suku ke 5 = 16.375 suku ke 6 = 18.4 hasil selisih = 2.0249999999999986 suku ke 6 = 18.4 suku ke 7 = 19.412499999999998 hasil selisih = 1.0124999999999993 suku ke 7 = 19.412499999999998 suku ke 8 = 19.846428571428568 hasil selisih = 0.4339285714285701 suku ke 8 = 19.846428571428568 suku ke 9 = 20.009151785714284 hasil selisih = 0.162723214285716 suku ke 9 = 20.009151785714284 suku ke 10 = 20.063392857142855 hasil selisih = 0.05424107142857082 suku ke 10 = 20.063392857142855 suku ke 11 = 20.079665178571425 hasil selisih = 0.016272321428569825 suku ke 11 = 20.079665178571425 suku ke 12 = 20.08410308441558 hasil selisih = 0.004437905844156376 suku ke 12 = 20.08410308441558 suku ke 13 = 20.08521256087662 hasil selisih = 0.001109476461039094 suku ke 13 = 20.08521256087662 suku ke 14 = 20.08546859390609 hasil selisih = 0.0002560330294691937","title":"error"},{"location":"error/#error-dalam-komputasi-numerik","text":"","title":"ERROR DALAM KOMPUTASI NUMERIK"},{"location":"error/#error","text":"Komputasi numerik bisa di artikan dengan penentuan eror suatu perhitungan agar bisa mencapai nilai akurasi. eror ini ialah nilai yang disebabkan nilai menjadi tidak tepat.","title":"ERROR"},{"location":"error/#penyebab-terjadinya-error","text":"Error dapat terjadi karena beberapa kesalahan. Berikut ini penjelasan mengenai ketiga sumber kesalahan dalam komputasi numerik. Round off errors Kesalahan jenis ini terjadi akibat proses pembulatan dalam perhitungan. Secara umum, proses pembulatan ada 2 aturan yaitu Jika digit yang dibulatkan kurang dari 5, maka tidak terjadi pembulatan. Sebaliknya, jika lebih dari 5, maka terjadi pembulatan yaitu dengan menambah satu. Truncation errors Truncation errors adalah kesalahan yang dilakukan dengan memotong jumlah tak hingga dan memperkirakannya dengan jumlah terbatas. Inherent errors Terjadi akibat kekeliruan dalam menyalin data, salah membaca skala atau kesalahan karena kurangnya pengertian mengenai hukum-hukum fisik dari data yang diukur. Kesalahan ini sering terjadi karena faktor human error","title":"Penyebab Terjadinya Error"},{"location":"error/#deret-maclaurin","text":"Deret MacLaurin adalah Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret Taylor.","title":"DERET MACLAURIN"},{"location":"error/#perhitungan-e2x","text":"Dalam banyak masalah terapan, pilihan basis yang mudah digunakan adalah bilangan irasional e = 2,718281828... Bilangan ini disebut basis natural. Fungsi f ( x ) = ex disebut sebagai fungsi eksponensial natural. Gambar 7 menunjukkan grafik fungsi ini. Pastikan bahwa dalam melihat fungsi eksponensial f ( x ) = ex , e adalah konstanta 2,718281828\u2026, sedangkan x adalah variabel. f(x)=ex f'(x) = ex maka f'(0) = 1 f\u201d(x) = ex maka f\u201d(0) = 1 f\u201d'(x) = ex maka f\u201d'(0) = 1 Untuk bilangan e 2x maka: jadi, kesimpulannya adalah sebagai berikut: ketika nilai x diganti dengan 4 maka hasilnya adalah 296,99.","title":"Perhitungan e2x"},{"location":"error/#listing-program","text":"Untuk membuat program agar dapat mengekspansi bilangan e 2x dengan nilai x=4 hingga nilai menjadi kurang dari 0,001 bisa dibuat dengan listing program sebagai berikut. import math x = int ( input ( \"masukan nilai x=\" )) cek = 1 a = 0 b = 1 while cek > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 3 ** i ) * x ** i / math . factorial ( i ) for j in range ( b ): f_y += ( 3 ** j ) * x ** j / math . factorial ( j ) print ( \"suku ke\" , a , \"=\" , f_x ) print ( \"suku ke\" , b , \"=\" , f_y ) cek = f_y - f_x a += 1 b += 1 print ( \"hasil selisih =\" , cek ) dan berikut hasil output nya : masukan nilai x = 1 suku ke 0 = 0 suku ke 1 = 1.0 hasil selisih = 1.0 suku ke 1 = 1.0 suku ke 2 = 4.0 hasil selisih = 3.0 suku ke 2 = 4.0 suku ke 3 = 8.5 hasil selisih = 4.5 suku ke 3 = 8.5 suku ke 4 = 13.0 hasil selisih = 4.5 suku ke 4 = 13.0 suku ke 5 = 16.375 hasil selisih = 3.375 suku ke 5 = 16.375 suku ke 6 = 18.4 hasil selisih = 2.0249999999999986 suku ke 6 = 18.4 suku ke 7 = 19.412499999999998 hasil selisih = 1.0124999999999993 suku ke 7 = 19.412499999999998 suku ke 8 = 19.846428571428568 hasil selisih = 0.4339285714285701 suku ke 8 = 19.846428571428568 suku ke 9 = 20.009151785714284 hasil selisih = 0.162723214285716 suku ke 9 = 20.009151785714284 suku ke 10 = 20.063392857142855 hasil selisih = 0.05424107142857082 suku ke 10 = 20.063392857142855 suku ke 11 = 20.079665178571425 hasil selisih = 0.016272321428569825 suku ke 11 = 20.079665178571425 suku ke 12 = 20.08410308441558 hasil selisih = 0.004437905844156376 suku ke 12 = 20.08410308441558 suku ke 13 = 20.08521256087662 hasil selisih = 0.001109476461039094 suku ke 13 = 20.08521256087662 suku ke 14 = 20.08546859390609 hasil selisih = 0.0002560330294691937","title":"Listing Program"},{"location":"fuzzy%20clustering/","text":"fuzzy clustering \u00b6 pengertian fuzzy clustering: \u00b6 Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0} ; FPC = {1:.2f} ' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"fuzzy clustering"},{"location":"fuzzy%20clustering/#fuzzy-clustering","text":"","title":"fuzzy clustering"},{"location":"fuzzy%20clustering/#pengertian-fuzzy-clustering","text":"Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0} ; FPC = {1:.2f} ' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"pengertian fuzzy clustering:"},{"location":"mencari%20akar/","text":"MENCARI AKAR PERSAMAAN \u00b6 Dalam matematika dan komputasi, algoritma pencarian akar adalah algoritma untuk menemukan nol, juga disebut \"root\", dari fungsi kontinu. Nol fungsi f , dari bilangan real ke bilangan real atau dari bilangan kompleks ke bilangan kompleks, adalah bilangan x sedemikian rupa sehingga f ( x ) = 0. 1. Metode Bisection \u00b6 Metode bagi dua (Bisection) disebut juga pemotongan biner (binary chopping), metode pembagian dua (interval halving). Prinsip metode bagi dua adalah mengurung akar fungsi pada interval [a,b]. Selanjutnya interval tersebut terus menerus dibagi dua hingga sekecil mungkin, sehingga nilai hampiran yang dicari dapat ditentukan dengan tingkat akurasi tertentu. Menentuka selang [a,b] sehingga f(a).f(b) < 0. Pada setiap kali lelaran, selang [a,b] kita bagi dua di x=c, sehingga terdapat dua buah upaselang yang berukuran sama, yaitu [a,c] dan [c,b]. selang yang diambil untuk lelaran berikutnya adalah upaselang yang memuat akat, tergantung pada apakah f(a). f(c)< 0 atau f(c)f(b) < 0. Selang yang baru dibagu dua lagi dengan cara yang samaa. Begituseterusnya sampai ukuran selang yang baru sudah sangat kecil. Kondisiberhenti lelaran dapat dipilih salah satu dari tiga kriteria berikut: Bisection adalah algoritma pencarian akar pada sebuah interval. Interval tersebut membagi dua bagian, lalu memilih dari dua bagian ini dipilih bagian mana yang mengandung akar dan bagian yang tidak mengandung akar dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh akar persamaan atau mendekati akar persamaan. Metode ini berlaku ketika ingin memecahkan persamaan f ( x ) = 0 dengan f merupakan fungsi kontinyu. Rumus bisection : f (a)* f (b) < 0 Prosedur Metode Bagi-Dua : Misal dijamin bahwa f(x) adalah fungsi kontinyu pada interval [a, b] dan f (a) f (b) < 0. Ini artinya bahwa f(x) paling tidak harus memiliki akar pada interval [a, b]. Kemudian definisikan titik tengah pada interval [a, b] yaitu c :=. Dari sini kita memperoleh dua subinterval yaitu [a, c] dan [c, b]. Setelah itu, cek apakah f (a) f (c) < 0 atau f (b) f (c) < 0 ? Jika f (a) f (c) < 0 maka b = c (artinya titik b digantikan oleh titik c yang berfungsi sebagai titik b pada iterasi berikutnya), jika tidak maka a = c. Dari iterasi pertama kita memperoleh interval [a, b] yang baru dan titik tengah c yang baru. Kemudian lakukan pengecekan lagi seperti sebelumnya sampai memperoleh error yang cukup kecil. ```py def bisection(f,a,b,N): if f(a)*f(b) >= 0: print(\"Bisection method fails.\") return None a_n = a b_n = b for n in range(1,N+1): m_n = (a_n + b_n)/2 f_m_n = f(m_n) if f(a_n)*f_m_n < 0: a_n = a_n b_n = m_n print (\"a = \",a_n) print (\"b = \",b_n) elif f(b_n)*f_m_n < 0: a_n = m_n b_n = b_n print (\"a = \",a_n) print (\"b = \",b_n) elif f_m_n == 0: print(\"Found exact solution.\") return m_n else: print(\"Bisection method fails.\") return None return (a_n + b_n)/2 f = lambda x: x 2 - 5*x +6 approx_phi = bisection(f,0,2.5,25) print(\"x = \",approx_phi) ##error_bound = 2 (-26) ##print(error_bound) ##print(abs( (1 + 5**0.5)/2 - approx_phi) < error_bound) ``` Python 3.7 . 3 ( v3 . 7.3 : ef4ec6ed12 , Mar 25 2019 , 21 : 26 : 53 ) [ MSC v . 1916 32 bit ( Intel )] on win32 Type \"help\" , \"copyright\" , \"credits\" or \"license()\" for more information . >>> ======== RESTART : C : \\ Users \\ USER \\ Downloads \\ langsung hapus \\ bisection . py ======== a = 1.75 b = 2.5 a = 1.75 b = 2.125 a = 1.9375 b = 2.125 a = 1.9375 b = 2.03125 a = 1.984375 b = 2.03125 a = 1.984375 b = 2.0078125 a = 1.99609375 b = 2.0078125 a = 1.99609375 b = 2.001953125 a = 1.9990234375 b = 2.001953125 a = 1.9990234375 b = 2.00048828125 a = 1.999755859375 b = 2.00048828125 a = 1.999755859375 b = 2.0001220703125 a = 1.99993896484375 b = 2.0001220703125 a = 1.99993896484375 b = 2.000030517578125 a = 1.9999847412109375 b = 2.000030517578125 a = 1.9999847412109375 b = 2.0000076293945312 a = 1.9999961853027344 b = 2.0000076293945312 a = 1.9999961853027344 b = 2.000001907348633 a = 1.9999990463256836 b = 2.000001907348633 a = 1.9999990463256836 b = 2.000000476837158 a = 1.999999761581421 b = 2.000000476837158 a = 1.999999761581421 b = 2.0000001192092896 a = 1.9999999403953552 b = 2.0000001192092896 a = 1.9999999403953552 b = 2.0000000298023224 a = 1.9999999850988388 b = 2.0000000298023224 x = 2.0000000074505806 >>> 2. Metode Newtoon - Raphson \u00b6 Metode Newton-Raphson adalah sebuah metode yang tentu saja ditemukan oleh Issac Newton melalui sebuah pendekatan yang menggunakan satu titik awal dan mendekatinya dengan memperhatikan kemiringan kurva pada titik tersebut. Penjelasan grafis mengenai lebih lanjut terhadap metode ini bisa dilihat pada gambar dibawah ini. Diasumsikan bahwa fungsi f(x) adalah kontinu. Idenya adalah menghitung akar yang merupakan titik potong antara sumbu x dengan garis singgung pada kurva di titik (xn-1; f (xn-1)). Kemiringan kurva di titik tersebut adalah f\u201d (xn-1), sehingga garis singgung mempunyai persamaan sebagai berikut : karena itu maka diperoleh sebuah akar perkiraan dengan mengambil sebuah nilai y = 0, sehingga akan menghasilkan sebuah persamaan lagi yang baru yaitu : def newton(f,Df,x0,epsilon,max_iter): xn = x0 for n in range(0,max_iter): fxn = f(xn) if abs(fxn) < epsilon: print('Found solution after',n,'iterations.') return xn Dfxn = Df(xn) if Dfxn == 0: print('Zero derivative. No solution found.') return None xn = xn - fxn/Dfxn print('Exceeded maximum iterations. No solution found.') return None p = lambda x: x**3 - x**2 - 1 Dp = lambda x: 3*x**2 - 2*x approx = newton(p,Dp,1,1e-10,10) print(approx) ##f = lambda x: x**(1/3) ##Df = lambda x: (1/3)*x**(-2/3) ##approx = newton(f,Df,0.1,1e-2,100) Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 21:26:53) [MSC v.1916 32 bit (Intel)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license()\" for more information. >>> ====== RESTART: C:\\Users\\USER\\Downloads\\langsung hapus\\Newton_method.py ====== Found solution after 6 iterations. 1.4655712318767877 >>> 3. Metode Regula - Falsi \u00b6 Metode Regula Falsi adalah salah satu metode numerik yang digunakan untuk mencari akar dari suatu persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dari dua titik batas range. Sebenarnya metode ini hampir sama dengan Metode Biseksi, tapi titik pendekatan yang digunakan pada metode ini berbeda dengan Metode Biseksi. Rumus titik pendekatan tersebut adalah : Keterangan : a = X0 b = X1 m = X2 Metode regula falsi merupakan salah satu metode tertutup untuk menentukan solusi akar dari persamaan non linier. Berikut langkah penyelesaiannya : 1) Tentukan interval [X0, X1] yang memuat akar 2) Tentukan titik X2 dengan menarik garis lurus dari titik [X0, f (X0)] ke titik [X1, f (X1)] titik X2 adalah titik potong garis dengan sumbu X. X2 = X0 * f (X1) - X1 * f (X0) / f (X1) - f (X0) X2 = X1 - [ (X1 -X0) / f (X1) - f (X0) ] * f (X1) [P] X2 = X1 - P * f (X1) 3) Suatu kondisi bila : f (X0) * f (X2) < 0 Maka akar pada [X0, X2] , X2 = X1 f (X0) * f (X2) = 0 akar = X2 f (X0) * f (X2) > 0 Maka akar pada [X2, X1], X2 = X0 4) Pengulangan / iterasi mencari X2 dan interval baru dilakukan berdasarkan nilai toleransi | (X2 - X)1 / X1 | atau | (X2 - X0) / X0 | 5) Kelemahan : Hanya salah satu ujung titik interval ( X0 atau X1 ) yang bergerak menuju akar dan yang lain selalu tetap untuk setiap iterasi [ nilai bersifat mutlak ] error = 0.01 a = 0 b = 2.1 def f ( x ): return x ** 2 - 5 * x + 6 def regulasi_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x print ( x ) if f ( x ) * f ( b ) < 0 : a = x print ( x ) if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regulasi_falsi ( a , b ) Python 3.7 . 3 ( v3 . 7.3 : ef4ec6ed12 , Mar 25 2019 , 21 : 26 : 53 ) [ MSC v . 1916 32 bit ( Intel )] on win32 Type \"help\" , \"copyright\" , \"credits\" or \"license()\" for more information . >>> ====== RESTART : C : \\ Users \\ USER \\ Downloads \\ langsung hapus \\ regula falsi . py ====== 2.0689655172413794 2.047058823529412 2.03187250996016 2.0214765100671146 2.0144209103199646 2.009660377358491 2.0064610569885417 2.004316668071832 2.0028819254864656 2.0019231310978185 2.0012829097997895 2.0008556391024563 2.0005705888076695 2.0003804649014514 2.0002536754391684 2.000169131260928 2.0001127605310622 2.000075176513023 2.0000501189312705 2.0000334131790583 2.000022275700806 2.0000148505774735 2.0000099004339917 2.00000660031111 2.0000044002170876 2.0000029334823615 2.0000019556568196 2.0000013037720628 2.000000869181753 2.00000057945467 2.0000003863031877 2.000000257535491 2.000000171690342 2.0000001144602346 2.0000000763068257 2.000000050871219 2.0000000339141466 2.0000000226094317 2.000000015072955 2.000000010048637 2.000000006699091 2.000000004466061 2.0000000029773735 2.000000001984916 2.0000000013232775 2.000000000882185 2.0000000005881233 2.0000000003920824 2.000000000261388 2.000000000174259 x = 2.000000000174259 >>> 4. Metode Secant \u00b6 Metode secant merupakan perbaikan dari metode regula-falsi dan newton raphson dimana kemiringan dua titik dinyatakan sacara diskrit, dengan mengambil bentuk garis lurus yang melalui satu titik. Tujuan metode secant adalah untuk menyelesaikan masalah yang terdapat pada metode Newton-Raphson yang terkadang sulit mendapatkan turunan pertama yaitu f\u2018 (x) . Fungsi metode secant adalah untuk menaksirkan akar dengan menggunakan diferensi daripada turunan untuk memperkirakan kemiringan/slope. f\u2019 (x) = ( f (xn) \u2013 f (xn-1)) / *(xn \u2013 xn-1) xn+1 = xn \u2013 ( ( f(xn) (xn \u2013 xn-1)) / ( f(xn) -f(xn-1) )** Algoritma Metode Secant : Definisikan fungsi f(x) Definisikan torelansi error (e) dan iterasi maksimum (n) Masukkan dua nilai pendekatan awal yang di antaranya terdapat akar yaitu x0 dan x1,sebaiknya gunakan metode tabel atau grafis untuk menjamin titik pendakatannya adalah titik pendekatan yang konvergensinya pada akar persamaan yang diharapkan. Hitung f(x0) dan f(x1) sebagai y0 dan y1 Untuk iterasi I = 1 s/d n atau | f(xn) | Xn+1 = Xn \u2013 Yn (Xn \u2013 Xn-1 / Yn \u2013 Yn-1) Akar persamaan adalah nilai x yang terakhir. ```pyt ``` def secant ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Secant method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Secant method fails.\" ) return None return a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) p = lambda x : x ** 2 - 5 * x + 6 print ( p ( 1 )) print ( p ( 2 )) approx = secant ( p , 1 , 2.5 , 25 ) print ( approx ) Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 21:26:53) [MSC v.1916 32 bit (Intel)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license()\" for more information. >>> ====== RESTART: C:\\Users\\USER\\Downloads\\langsung hapus\\secant_method.py ====== 2 0 2.0000000149011603 >>>","title":"mencari akar"},{"location":"mencari%20akar/#mencari-akar-persamaan","text":"Dalam matematika dan komputasi, algoritma pencarian akar adalah algoritma untuk menemukan nol, juga disebut \"root\", dari fungsi kontinu. Nol fungsi f , dari bilangan real ke bilangan real atau dari bilangan kompleks ke bilangan kompleks, adalah bilangan x sedemikian rupa sehingga f ( x ) = 0.","title":"MENCARI AKAR PERSAMAAN"},{"location":"mencari%20akar/#1-metode-bisection","text":"Metode bagi dua (Bisection) disebut juga pemotongan biner (binary chopping), metode pembagian dua (interval halving). Prinsip metode bagi dua adalah mengurung akar fungsi pada interval [a,b]. Selanjutnya interval tersebut terus menerus dibagi dua hingga sekecil mungkin, sehingga nilai hampiran yang dicari dapat ditentukan dengan tingkat akurasi tertentu. Menentuka selang [a,b] sehingga f(a).f(b) < 0. Pada setiap kali lelaran, selang [a,b] kita bagi dua di x=c, sehingga terdapat dua buah upaselang yang berukuran sama, yaitu [a,c] dan [c,b]. selang yang diambil untuk lelaran berikutnya adalah upaselang yang memuat akat, tergantung pada apakah f(a). f(c)< 0 atau f(c)f(b) < 0. Selang yang baru dibagu dua lagi dengan cara yang samaa. Begituseterusnya sampai ukuran selang yang baru sudah sangat kecil. Kondisiberhenti lelaran dapat dipilih salah satu dari tiga kriteria berikut: Bisection adalah algoritma pencarian akar pada sebuah interval. Interval tersebut membagi dua bagian, lalu memilih dari dua bagian ini dipilih bagian mana yang mengandung akar dan bagian yang tidak mengandung akar dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh akar persamaan atau mendekati akar persamaan. Metode ini berlaku ketika ingin memecahkan persamaan f ( x ) = 0 dengan f merupakan fungsi kontinyu. Rumus bisection : f (a)* f (b) < 0 Prosedur Metode Bagi-Dua : Misal dijamin bahwa f(x) adalah fungsi kontinyu pada interval [a, b] dan f (a) f (b) < 0. Ini artinya bahwa f(x) paling tidak harus memiliki akar pada interval [a, b]. Kemudian definisikan titik tengah pada interval [a, b] yaitu c :=. Dari sini kita memperoleh dua subinterval yaitu [a, c] dan [c, b]. Setelah itu, cek apakah f (a) f (c) < 0 atau f (b) f (c) < 0 ? Jika f (a) f (c) < 0 maka b = c (artinya titik b digantikan oleh titik c yang berfungsi sebagai titik b pada iterasi berikutnya), jika tidak maka a = c. Dari iterasi pertama kita memperoleh interval [a, b] yang baru dan titik tengah c yang baru. Kemudian lakukan pengecekan lagi seperti sebelumnya sampai memperoleh error yang cukup kecil. ```py def bisection(f,a,b,N): if f(a)*f(b) >= 0: print(\"Bisection method fails.\") return None a_n = a b_n = b for n in range(1,N+1): m_n = (a_n + b_n)/2 f_m_n = f(m_n) if f(a_n)*f_m_n < 0: a_n = a_n b_n = m_n print (\"a = \",a_n) print (\"b = \",b_n) elif f(b_n)*f_m_n < 0: a_n = m_n b_n = b_n print (\"a = \",a_n) print (\"b = \",b_n) elif f_m_n == 0: print(\"Found exact solution.\") return m_n else: print(\"Bisection method fails.\") return None return (a_n + b_n)/2 f = lambda x: x 2 - 5*x +6 approx_phi = bisection(f,0,2.5,25) print(\"x = \",approx_phi) ##error_bound = 2 (-26) ##print(error_bound) ##print(abs( (1 + 5**0.5)/2 - approx_phi) < error_bound) ``` Python 3.7 . 3 ( v3 . 7.3 : ef4ec6ed12 , Mar 25 2019 , 21 : 26 : 53 ) [ MSC v . 1916 32 bit ( Intel )] on win32 Type \"help\" , \"copyright\" , \"credits\" or \"license()\" for more information . >>> ======== RESTART : C : \\ Users \\ USER \\ Downloads \\ langsung hapus \\ bisection . py ======== a = 1.75 b = 2.5 a = 1.75 b = 2.125 a = 1.9375 b = 2.125 a = 1.9375 b = 2.03125 a = 1.984375 b = 2.03125 a = 1.984375 b = 2.0078125 a = 1.99609375 b = 2.0078125 a = 1.99609375 b = 2.001953125 a = 1.9990234375 b = 2.001953125 a = 1.9990234375 b = 2.00048828125 a = 1.999755859375 b = 2.00048828125 a = 1.999755859375 b = 2.0001220703125 a = 1.99993896484375 b = 2.0001220703125 a = 1.99993896484375 b = 2.000030517578125 a = 1.9999847412109375 b = 2.000030517578125 a = 1.9999847412109375 b = 2.0000076293945312 a = 1.9999961853027344 b = 2.0000076293945312 a = 1.9999961853027344 b = 2.000001907348633 a = 1.9999990463256836 b = 2.000001907348633 a = 1.9999990463256836 b = 2.000000476837158 a = 1.999999761581421 b = 2.000000476837158 a = 1.999999761581421 b = 2.0000001192092896 a = 1.9999999403953552 b = 2.0000001192092896 a = 1.9999999403953552 b = 2.0000000298023224 a = 1.9999999850988388 b = 2.0000000298023224 x = 2.0000000074505806 >>>","title":"1. Metode Bisection"},{"location":"mencari%20akar/#2-metode-newtoon-raphson","text":"Metode Newton-Raphson adalah sebuah metode yang tentu saja ditemukan oleh Issac Newton melalui sebuah pendekatan yang menggunakan satu titik awal dan mendekatinya dengan memperhatikan kemiringan kurva pada titik tersebut. Penjelasan grafis mengenai lebih lanjut terhadap metode ini bisa dilihat pada gambar dibawah ini. Diasumsikan bahwa fungsi f(x) adalah kontinu. Idenya adalah menghitung akar yang merupakan titik potong antara sumbu x dengan garis singgung pada kurva di titik (xn-1; f (xn-1)). Kemiringan kurva di titik tersebut adalah f\u201d (xn-1), sehingga garis singgung mempunyai persamaan sebagai berikut : karena itu maka diperoleh sebuah akar perkiraan dengan mengambil sebuah nilai y = 0, sehingga akan menghasilkan sebuah persamaan lagi yang baru yaitu : def newton(f,Df,x0,epsilon,max_iter): xn = x0 for n in range(0,max_iter): fxn = f(xn) if abs(fxn) < epsilon: print('Found solution after',n,'iterations.') return xn Dfxn = Df(xn) if Dfxn == 0: print('Zero derivative. No solution found.') return None xn = xn - fxn/Dfxn print('Exceeded maximum iterations. No solution found.') return None p = lambda x: x**3 - x**2 - 1 Dp = lambda x: 3*x**2 - 2*x approx = newton(p,Dp,1,1e-10,10) print(approx) ##f = lambda x: x**(1/3) ##Df = lambda x: (1/3)*x**(-2/3) ##approx = newton(f,Df,0.1,1e-2,100) Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 21:26:53) [MSC v.1916 32 bit (Intel)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license()\" for more information. >>> ====== RESTART: C:\\Users\\USER\\Downloads\\langsung hapus\\Newton_method.py ====== Found solution after 6 iterations. 1.4655712318767877 >>>","title":"2. Metode Newtoon - Raphson"},{"location":"mencari%20akar/#3-metode-regula-falsi","text":"Metode Regula Falsi adalah salah satu metode numerik yang digunakan untuk mencari akar dari suatu persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dari dua titik batas range. Sebenarnya metode ini hampir sama dengan Metode Biseksi, tapi titik pendekatan yang digunakan pada metode ini berbeda dengan Metode Biseksi. Rumus titik pendekatan tersebut adalah : Keterangan : a = X0 b = X1 m = X2 Metode regula falsi merupakan salah satu metode tertutup untuk menentukan solusi akar dari persamaan non linier. Berikut langkah penyelesaiannya : 1) Tentukan interval [X0, X1] yang memuat akar 2) Tentukan titik X2 dengan menarik garis lurus dari titik [X0, f (X0)] ke titik [X1, f (X1)] titik X2 adalah titik potong garis dengan sumbu X. X2 = X0 * f (X1) - X1 * f (X0) / f (X1) - f (X0) X2 = X1 - [ (X1 -X0) / f (X1) - f (X0) ] * f (X1) [P] X2 = X1 - P * f (X1) 3) Suatu kondisi bila : f (X0) * f (X2) < 0 Maka akar pada [X0, X2] , X2 = X1 f (X0) * f (X2) = 0 akar = X2 f (X0) * f (X2) > 0 Maka akar pada [X2, X1], X2 = X0 4) Pengulangan / iterasi mencari X2 dan interval baru dilakukan berdasarkan nilai toleransi | (X2 - X)1 / X1 | atau | (X2 - X0) / X0 | 5) Kelemahan : Hanya salah satu ujung titik interval ( X0 atau X1 ) yang bergerak menuju akar dan yang lain selalu tetap untuk setiap iterasi [ nilai bersifat mutlak ] error = 0.01 a = 0 b = 2.1 def f ( x ): return x ** 2 - 5 * x + 6 def regulasi_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x print ( x ) if f ( x ) * f ( b ) < 0 : a = x print ( x ) if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regulasi_falsi ( a , b ) Python 3.7 . 3 ( v3 . 7.3 : ef4ec6ed12 , Mar 25 2019 , 21 : 26 : 53 ) [ MSC v . 1916 32 bit ( Intel )] on win32 Type \"help\" , \"copyright\" , \"credits\" or \"license()\" for more information . >>> ====== RESTART : C : \\ Users \\ USER \\ Downloads \\ langsung hapus \\ regula falsi . py ====== 2.0689655172413794 2.047058823529412 2.03187250996016 2.0214765100671146 2.0144209103199646 2.009660377358491 2.0064610569885417 2.004316668071832 2.0028819254864656 2.0019231310978185 2.0012829097997895 2.0008556391024563 2.0005705888076695 2.0003804649014514 2.0002536754391684 2.000169131260928 2.0001127605310622 2.000075176513023 2.0000501189312705 2.0000334131790583 2.000022275700806 2.0000148505774735 2.0000099004339917 2.00000660031111 2.0000044002170876 2.0000029334823615 2.0000019556568196 2.0000013037720628 2.000000869181753 2.00000057945467 2.0000003863031877 2.000000257535491 2.000000171690342 2.0000001144602346 2.0000000763068257 2.000000050871219 2.0000000339141466 2.0000000226094317 2.000000015072955 2.000000010048637 2.000000006699091 2.000000004466061 2.0000000029773735 2.000000001984916 2.0000000013232775 2.000000000882185 2.0000000005881233 2.0000000003920824 2.000000000261388 2.000000000174259 x = 2.000000000174259 >>>","title":"3. Metode Regula - Falsi"},{"location":"mencari%20akar/#4-metode-secant","text":"Metode secant merupakan perbaikan dari metode regula-falsi dan newton raphson dimana kemiringan dua titik dinyatakan sacara diskrit, dengan mengambil bentuk garis lurus yang melalui satu titik. Tujuan metode secant adalah untuk menyelesaikan masalah yang terdapat pada metode Newton-Raphson yang terkadang sulit mendapatkan turunan pertama yaitu f\u2018 (x) . Fungsi metode secant adalah untuk menaksirkan akar dengan menggunakan diferensi daripada turunan untuk memperkirakan kemiringan/slope. f\u2019 (x) = ( f (xn) \u2013 f (xn-1)) / *(xn \u2013 xn-1) xn+1 = xn \u2013 ( ( f(xn) (xn \u2013 xn-1)) / ( f(xn) -f(xn-1) )** Algoritma Metode Secant : Definisikan fungsi f(x) Definisikan torelansi error (e) dan iterasi maksimum (n) Masukkan dua nilai pendekatan awal yang di antaranya terdapat akar yaitu x0 dan x1,sebaiknya gunakan metode tabel atau grafis untuk menjamin titik pendakatannya adalah titik pendekatan yang konvergensinya pada akar persamaan yang diharapkan. Hitung f(x0) dan f(x1) sebagai y0 dan y1 Untuk iterasi I = 1 s/d n atau | f(xn) | Xn+1 = Xn \u2013 Yn (Xn \u2013 Xn-1 / Yn \u2013 Yn-1) Akar persamaan adalah nilai x yang terakhir. ```pyt ``` def secant ( f , a , b , N ): if f ( a ) * f ( b ) >= 0 : print ( \"Secant method fails.\" ) return None a_n = a b_n = b for n in range ( 1 , N + 1 ): m_n = a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) f_m_n = f ( m_n ) if f ( a_n ) * f_m_n < 0 : a_n = a_n b_n = m_n elif f ( b_n ) * f_m_n < 0 : a_n = m_n b_n = b_n elif f_m_n == 0 : print ( \"Found exact solution.\" ) return m_n else : print ( \"Secant method fails.\" ) return None return a_n - f ( a_n ) * ( b_n - a_n ) / ( f ( b_n ) - f ( a_n )) p = lambda x : x ** 2 - 5 * x + 6 print ( p ( 1 )) print ( p ( 2 )) approx = secant ( p , 1 , 2.5 , 25 ) print ( approx ) Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 21:26:53) [MSC v.1916 32 bit (Intel)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license()\" for more information. >>> ====== RESTART: C:\\Users\\USER\\Downloads\\langsung hapus\\secant_method.py ====== 2 0 2.0000000149011603 >>>","title":"4. Metode Secant"},{"location":"missing%20value/","text":"Memperlakukan Missing Value Dengan Metode Algoritma K-Nearest Neighbor (KNN) \u00b6 Missing Value \u00b6 Missing value adalah informasi yang tidak tersedia untuk sebuah objek (kasus). Missing value terjadi karena informasi untuk sesuatu tentang objek tidak diberikan, sulit dicari, atau memang informasi tersebut tidak ada. Missing value pada dasarnya tidak bermasalah bagi keseluruhan data, apalagi jika jumlahnya hanya sedikit, misal hanya 1 % dari seluruh data. Namun jika persentase data yang hilang tersebut cukup besar, maka perlu dilakukan pengujian apakah data yang meng kita dapat menggunakan metode Algoritma K-Nearest Neighbor (KKN). K-Nearest Neighbor (KNN) \u00b6 Salah satu usaha untuk memperlakukan missing data yaitu dengan menggunakan Algoritma K-Nearest Neighbor (KNN). Lalu apa yang dimaksud dengan KNN? Algoritma K-Nearest Neighbor (K-NN) adalah sebuah metode klasifikasi terhadap sekumpulan data berdasarkan pembelajaran data yang sudah terklasifikasikan sebelumya. Termasuk dalam supervised learning , dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas kedekatan jarak dari kategori yang ada dalam K-NN . Algroritma pada K-Nearest Neighbor (KNN) \u00b6 Langkah utama dalam metode KNN yaitu dengan menghitung nilai k. Nilai k yang dimaksud yaitu jarak tetangga terdekat antar dataset. Kemudian, hasil perhitungan nilai k tersebut menjadi nilai estimator yang digunakan untuk mengisi pada data yang hilang tersebut. Perhitungan untuk mencari nilai k yaitu tergantung dengan jenis data. Apabila data yang disajikan berupa data kontinu, maka menggunakan rata-rata dari tetangga terdekat. Dan apabila data yang disajikan berupa data kualitatif, maka diambil dari nilai yang sering keluar pada objek. Dapat dimisalkan bahwa D merupakan suatu objek yang memiliki kasus missing data. Dengan Dc merupakan subdata yang lengkap, sedangkan Dm merupakan sub data yang memiliki kerumpangan (mengandung atribut yang hilang). Maka, tahapan langkah algoritma pada KKN sebagai berikut : Menentukan parameter k (jumlah tetangga paling dekat). Menghitung kuadrat jarak eucliden objek terhadap data training yang diberikan. Mengurutkan hasil no 2 secara ascending (berurutan dari nilai tinggi ke rendah) Mengumpulkan kategori Y (Klasifikasi nearest neighbor berdasarkan nilai k) Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat dipredisikan kategori objek. # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 80 , np . nan , 65 ], 'Second Score' : [ 80 , 55 , 76 , np . nan ], 'Third Score' :[ np . nan , 60 , 90 , 87 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) First Score Second Score Third Score 0 100.0 80.0 0.0 1 80.0 55.0 60.0 2 0.0 76.0 90.0 3 65.0 0.0 87.0 MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} }); \u200b","title":"missing value"},{"location":"missing%20value/#memperlakukan-missing-value-dengan-metode-algoritma-k-nearest-neighbor-knn","text":"","title":"Memperlakukan Missing Value Dengan Metode  Algoritma K-Nearest Neighbor (KNN)"},{"location":"missing%20value/#missing-value","text":"Missing value adalah informasi yang tidak tersedia untuk sebuah objek (kasus). Missing value terjadi karena informasi untuk sesuatu tentang objek tidak diberikan, sulit dicari, atau memang informasi tersebut tidak ada. Missing value pada dasarnya tidak bermasalah bagi keseluruhan data, apalagi jika jumlahnya hanya sedikit, misal hanya 1 % dari seluruh data. Namun jika persentase data yang hilang tersebut cukup besar, maka perlu dilakukan pengujian apakah data yang meng kita dapat menggunakan metode Algoritma K-Nearest Neighbor (KKN).","title":"Missing Value"},{"location":"missing%20value/#k-nearest-neighbor-knn","text":"Salah satu usaha untuk memperlakukan missing data yaitu dengan menggunakan Algoritma K-Nearest Neighbor (KNN). Lalu apa yang dimaksud dengan KNN? Algoritma K-Nearest Neighbor (K-NN) adalah sebuah metode klasifikasi terhadap sekumpulan data berdasarkan pembelajaran data yang sudah terklasifikasikan sebelumya. Termasuk dalam supervised learning , dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas kedekatan jarak dari kategori yang ada dalam K-NN .","title":"K-Nearest Neighbor (KNN)"},{"location":"missing%20value/#algroritma-pada-k-nearest-neighbor-knn","text":"Langkah utama dalam metode KNN yaitu dengan menghitung nilai k. Nilai k yang dimaksud yaitu jarak tetangga terdekat antar dataset. Kemudian, hasil perhitungan nilai k tersebut menjadi nilai estimator yang digunakan untuk mengisi pada data yang hilang tersebut. Perhitungan untuk mencari nilai k yaitu tergantung dengan jenis data. Apabila data yang disajikan berupa data kontinu, maka menggunakan rata-rata dari tetangga terdekat. Dan apabila data yang disajikan berupa data kualitatif, maka diambil dari nilai yang sering keluar pada objek. Dapat dimisalkan bahwa D merupakan suatu objek yang memiliki kasus missing data. Dengan Dc merupakan subdata yang lengkap, sedangkan Dm merupakan sub data yang memiliki kerumpangan (mengandung atribut yang hilang). Maka, tahapan langkah algoritma pada KKN sebagai berikut : Menentukan parameter k (jumlah tetangga paling dekat). Menghitung kuadrat jarak eucliden objek terhadap data training yang diberikan. Mengurutkan hasil no 2 secara ascending (berurutan dari nilai tinggi ke rendah) Mengumpulkan kategori Y (Klasifikasi nearest neighbor berdasarkan nilai k) Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat dipredisikan kategori objek. # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 80 , np . nan , 65 ], 'Second Score' : [ 80 , 55 , 76 , np . nan ], 'Third Score' :[ np . nan , 60 , 90 , 87 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) First Score Second Score Third Score 0 100.0 80.0 0.0 1 80.0 55.0 60.0 2 0.0 76.0 90.0 3 65.0 0.0 87.0 MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} }); \u200b","title":"Algroritma pada K-Nearest Neighbor (KNN)"},{"location":"pohon%20keputusan/","text":"DECISION TREE \u00b6 Decision tree adalah salah satu metode klasifikasi yang paling populer, karena mudah untuk diinterpretasi oleh manusia. Decision tree merupakan model prediksi menggunakan struktur pohon atau struktur berhirarki. Setiap orang tentu menginginkan sebuah pengambilan keputusan yang tepat dan efisien tak terkecuali sebuah perusahaan. Untuk itu banyak sekali perusahaan yang membutuhkan suatu media seperti Business Intellegence guna membantu dalam pengambilan keputusan yang tepat. Namun, hal tersebut tidak akan berarti tanpa adanya konsep decision tree atau yang biasa disebut pohon keputusan. Konsep dari pohon keputusan adalah mengubah data menjadi decision tree dan aturan-aturan keputusan. Manfaat utama dari penggunaan decision tree adalah kemampuannya untuk mem- break down proses pengambilan keputusan yang kompleks menjadi lebih simple, sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Nama lain dari decision tree adalah CART ( Classification and Regression Tree ). Dimana metode ini merupakan gabungan dari dua jenis pohon, yaitu classification tree dan juga regression tree . Untuk memudahkan, berikut ilustrasi dari keduanya. Decision tree juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Decision tree memadukan antara eksplorasi data dan pemodelan, sehingga sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Entropy \u00b6 Entropi adalah nilai informasi yang menyatakan ukuran ketidakpastian(impurity) dari attribut dari suatu kumpulan obyek data dalam satuan bit. $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ Dimana : T = ruang sampel data yang digunakan untukdata pelatihan Pi = Probabiliti muncul dalam row Gain \u00b6 Information Gain adalah ukuran efektifitas suatu atribut dlm mengklasifikasikan data, digunakan untuk menentukan urutan atribut dimana attribut yang memiliki nilai Information Gain terbesar yang dipilih. $$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$ Dimana : Entropy (T) = nilai entropi total dari atribut keputusan dalam ruang sampel data T x = fitur CARA MEMBUAT DECISION TREE \u00b6 \u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 ## GINI INDEX Dalam penerapan GINI index untuk data berskala continuous, terdapat beberapa metode yang dapat digunakan untuk menentukan titik pemecah terbaik, yakni metode *brute-force* dan metode *midpoints*. # Importing the required packages import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report # Function importing Dataset def importdata (): balance_data = pd . read_csv ( 'https://archive.ics.uci.edu/ml/machine-learning-' + 'databases/balance-scale/balance-scale.data' , sep = ',' , header = None ) # Printing the dataswet shape print ( \"Dataset Length: \" , len ( balance_data )) print ( \"Dataset Shape: \" , balance_data . shape ) # Printing the dataset obseravtions print ( \"Dataset: \" , balance_data . head ()) return balance_data # Function to split the dataset def splitdataset ( balance_data ): # Seperating the target variable X = balance_data . values [:, 1 : 5 ] Y = balance_data . values [:, 0 ] # Spliting the dataset into train and test X_train , X_test , y_train , y_test = train_test_split ( X , Y , test_size = 0.3 , random_state = 100 ) return X , Y , X_train , X_test , y_train , y_test # Function to perform training with giniIndex. def train_using_gini ( X_train , X_test , y_train ): # Creating the classifier object clf_gini = DecisionTreeClassifier ( criterion = \"gini\" , random_state = 100 , max_depth = 3 , min_samples_leaf = 5 ) # Performing training clf_gini . fit ( X_train , y_train ) return clf_gini # Function to perform training with entropy. def tarin_using_entropy ( X_train , X_test , y_train ): # Decision tree with entropy clf_entropy = DecisionTreeClassifier ( criterion = \"entropy\" , random_state = 100 , max_depth = 3 , min_samples_leaf = 5 ) # Performing training clf_entropy . fit ( X_train , y_train ) return clf_entropy # Function to make predictions def prediction ( X_test , clf_object ): # Predicton on test with giniIndex y_pred = clf_object . predict ( X_test ) print ( \"Predicted values:\" ) print ( y_pred ) return y_pred # Function to calculate accuracy def cal_accuracy ( y_test , y_pred ): print ( \"Confusion Matrix: \" , confusion_matrix ( y_test , y_pred )) print ( \"Accuracy : \" , accuracy_score ( y_test , y_pred ) * 100 ) print ( \"Report : \" , classification_report ( y_test , y_pred )) # Driver code def main (): # Building Phase data = importdata () X , Y , X_train , X_test , y_train , y_test = splitdataset ( data ) clf_gini = train_using_gini ( X_train , X_test , y_train ) clf_entropy = tarin_using_entropy ( X_train , X_test , y_train ) # Operational Phase print ( \"Results Using Gini Index:\" ) # Prediction using gini y_pred_gini = prediction ( X_test , clf_gini ) cal_accuracy ( y_test , y_pred_gini ) print ( \"Results Using Entropy:\" ) # Prediction using entropy y_pred_entropy = prediction ( X_test , clf_entropy ) cal_accuracy ( y_test , y_pred_entropy ) # Calling main function if __name__ == \"__main__\" : main () Dataset Length : 625 Dataset Shape : ( 625 , 5 ) Dataset : 0 1 2 3 4 0 B 1 1 1 1 1 R 1 1 1 2 2 R 1 1 1 3 3 R 1 1 1 4 4 R 1 1 1 5 Results Using Gini Index : Predicted values : [ 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R' ] Confusion Matrix : [[ 0 6 7 ] [ 0 67 18 ] [ 0 19 71 ]] Accuracy : 73.40425531914893 Report : precision recall f1 - score support B 0.00 0.00 0.00 13 L 0.73 0.79 0.76 85 R 0.74 0.79 0.76 90 accuracy 0.73 188 macro avg 0.49 0.53 0.51 188 weighted avg 0.68 0.73 0.71 188 Results Using Entropy : Predicted values : [ 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' ] Confusion Matrix : [[ 0 6 7 ] [ 0 63 22 ] [ 0 20 70 ]] Accuracy : 70.74468085106383 Report : precision recall f1 - score support B 0.00 0.00 0.00 13 L 0.71 0.74 0.72 85 R 0.71 0.78 0.74 90 accuracy 0.71 188 macro avg 0.47 0.51 0.49 188 weighted avg 0.66 0.71 0.68 188 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); ]","title":"decision trees"},{"location":"pohon%20keputusan/#decision-tree","text":"Decision tree adalah salah satu metode klasifikasi yang paling populer, karena mudah untuk diinterpretasi oleh manusia. Decision tree merupakan model prediksi menggunakan struktur pohon atau struktur berhirarki. Setiap orang tentu menginginkan sebuah pengambilan keputusan yang tepat dan efisien tak terkecuali sebuah perusahaan. Untuk itu banyak sekali perusahaan yang membutuhkan suatu media seperti Business Intellegence guna membantu dalam pengambilan keputusan yang tepat. Namun, hal tersebut tidak akan berarti tanpa adanya konsep decision tree atau yang biasa disebut pohon keputusan. Konsep dari pohon keputusan adalah mengubah data menjadi decision tree dan aturan-aturan keputusan. Manfaat utama dari penggunaan decision tree adalah kemampuannya untuk mem- break down proses pengambilan keputusan yang kompleks menjadi lebih simple, sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Nama lain dari decision tree adalah CART ( Classification and Regression Tree ). Dimana metode ini merupakan gabungan dari dua jenis pohon, yaitu classification tree dan juga regression tree . Untuk memudahkan, berikut ilustrasi dari keduanya. Decision tree juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Decision tree memadukan antara eksplorasi data dan pemodelan, sehingga sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain.","title":"DECISION TREE"},{"location":"pohon%20keputusan/#entropy","text":"Entropi adalah nilai informasi yang menyatakan ukuran ketidakpastian(impurity) dari attribut dari suatu kumpulan obyek data dalam satuan bit. $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ Dimana : T = ruang sampel data yang digunakan untukdata pelatihan Pi = Probabiliti muncul dalam row","title":"Entropy"},{"location":"pohon%20keputusan/#gain","text":"Information Gain adalah ukuran efektifitas suatu atribut dlm mengklasifikasikan data, digunakan untuk menentukan urutan atribut dimana attribut yang memiliki nilai Information Gain terbesar yang dipilih. $$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$ Dimana : Entropy (T) = nilai entropi total dari atribut keputusan dalam ruang sampel data T x = fitur","title":"Gain"},{"location":"pohon%20keputusan/#cara-membuat-decision-tree","text":"\u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 ## GINI INDEX Dalam penerapan GINI index untuk data berskala continuous, terdapat beberapa metode yang dapat digunakan untuk menentukan titik pemecah terbaik, yakni metode *brute-force* dan metode *midpoints*. # Importing the required packages import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report # Function importing Dataset def importdata (): balance_data = pd . read_csv ( 'https://archive.ics.uci.edu/ml/machine-learning-' + 'databases/balance-scale/balance-scale.data' , sep = ',' , header = None ) # Printing the dataswet shape print ( \"Dataset Length: \" , len ( balance_data )) print ( \"Dataset Shape: \" , balance_data . shape ) # Printing the dataset obseravtions print ( \"Dataset: \" , balance_data . head ()) return balance_data # Function to split the dataset def splitdataset ( balance_data ): # Seperating the target variable X = balance_data . values [:, 1 : 5 ] Y = balance_data . values [:, 0 ] # Spliting the dataset into train and test X_train , X_test , y_train , y_test = train_test_split ( X , Y , test_size = 0.3 , random_state = 100 ) return X , Y , X_train , X_test , y_train , y_test # Function to perform training with giniIndex. def train_using_gini ( X_train , X_test , y_train ): # Creating the classifier object clf_gini = DecisionTreeClassifier ( criterion = \"gini\" , random_state = 100 , max_depth = 3 , min_samples_leaf = 5 ) # Performing training clf_gini . fit ( X_train , y_train ) return clf_gini # Function to perform training with entropy. def tarin_using_entropy ( X_train , X_test , y_train ): # Decision tree with entropy clf_entropy = DecisionTreeClassifier ( criterion = \"entropy\" , random_state = 100 , max_depth = 3 , min_samples_leaf = 5 ) # Performing training clf_entropy . fit ( X_train , y_train ) return clf_entropy # Function to make predictions def prediction ( X_test , clf_object ): # Predicton on test with giniIndex y_pred = clf_object . predict ( X_test ) print ( \"Predicted values:\" ) print ( y_pred ) return y_pred # Function to calculate accuracy def cal_accuracy ( y_test , y_pred ): print ( \"Confusion Matrix: \" , confusion_matrix ( y_test , y_pred )) print ( \"Accuracy : \" , accuracy_score ( y_test , y_pred ) * 100 ) print ( \"Report : \" , classification_report ( y_test , y_pred )) # Driver code def main (): # Building Phase data = importdata () X , Y , X_train , X_test , y_train , y_test = splitdataset ( data ) clf_gini = train_using_gini ( X_train , X_test , y_train ) clf_entropy = tarin_using_entropy ( X_train , X_test , y_train ) # Operational Phase print ( \"Results Using Gini Index:\" ) # Prediction using gini y_pred_gini = prediction ( X_test , clf_gini ) cal_accuracy ( y_test , y_pred_gini ) print ( \"Results Using Entropy:\" ) # Prediction using entropy y_pred_entropy = prediction ( X_test , clf_entropy ) cal_accuracy ( y_test , y_pred_entropy ) # Calling main function if __name__ == \"__main__\" : main () Dataset Length : 625 Dataset Shape : ( 625 , 5 ) Dataset : 0 1 2 3 4 0 B 1 1 1 1 1 R 1 1 1 2 2 R 1 1 1 3 3 R 1 1 1 4 4 R 1 1 1 5 Results Using Gini Index : Predicted values : [ 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R' ] Confusion Matrix : [[ 0 6 7 ] [ 0 67 18 ] [ 0 19 71 ]] Accuracy : 73.40425531914893 Report : precision recall f1 - score support B 0.00 0.00 0.00 13 L 0.73 0.79 0.76 85 R 0.74 0.79 0.76 90 accuracy 0.73 188 macro avg 0.49 0.53 0.51 188 weighted avg 0.68 0.73 0.71 188 Results Using Entropy : Predicted values : [ 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' ] Confusion Matrix : [[ 0 6 7 ] [ 0 63 22 ] [ 0 20 70 ]] Accuracy : 70.74468085106383 Report : precision recall f1 - score support B 0.00 0.00 0.00 13 L 0.71 0.74 0.72 85 R 0.71 0.78 0.74 90 accuracy 0.71 188 macro avg 0.47 0.51 0.49 188 weighted avg 0.66 0.71 0.68 188 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); ]","title":"CARA MEMBUAT DECISION TREE"},{"location":"tugas%201%20-%20Copy/","text":"Selamat Datang Di halaman Penambangan Data \u00b6 Nama : Kamaliya NIM : 180411100030 Kelas : Penambangan Data 5D Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : Jln.Sukun VI ,Perumnas Kamal \u00b6","title":"Selamat Datang Di halaman Penambangan Data"},{"location":"tugas%201%20-%20Copy/#selamat-datang-di-halaman-penambangan-data","text":"Nama : Kamaliya NIM : 180411100030 Kelas : Penambangan Data 5D Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : Jln.Sukun VI ,Perumnas Kamal","title":"Selamat Datang Di halaman Penambangan Data"},{"location":"tugas%201%20-%20Copy/#_1","text":"","title":""},{"location":"tugas%201/","text":"Selamat Datang Di halaman Saya \u00b6 Nama : Kamaliya NIM : 180411100030 Kelas : Komputasi Numerik 4B Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : Jln.Sukun VI ,Perumnas Kamal \u00b6 \u200b","title":"Selamat Datang Di halaman Saya"},{"location":"tugas%201/#selamat-datang-di-halaman-saya","text":"Nama : Kamaliya NIM : 180411100030 Kelas : Komputasi Numerik 4B Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : Jln.Sukun VI ,Perumnas Kamal","title":"Selamat Datang Di halaman Saya"},{"location":"tugas%201/#_1","text":"\u200b","title":""}]}